{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "document1 = [\"Bu Siti seorang pembuat kue yang sukses. Segala jenis kue yang dibuatnya rasanya enak dan laris manis ketika dijual.\",\n",
    "             \"Anak kembar yang masih duduk di bangku sekolah dasar itu memiliki sifat yang berlawanan. Rino salah satu dari anak kembar itu sangat baik dan rajin membantu orang tuanya bekerja di pasar. Sementara, Roni sepanjang hari kerjanya hanya bermain ponsel. Ia juga sering memaksa orang tuanya untuk membelikan pulsa dan menuruti semua keinginannya.\",\n",
    "             \"Keluarga Andi sangat baik. Mereka tinggal di desa Sukasari. Setiap ada tetangga yang kesulitan, mereka selalu membantunya dengan ikhlas. Mereka tidak pernah mengharapkan balas budi dari tetangga-tetangga yang pernah mereka bantu.Hari Sabtu kami pergi ke pantai. Di sana, kami melihat ombak besar, yang mana ombak itu menerjang kami yang sedang berada di pinggir pantai. Aku terempas ombak hingga ke tengah laut. Untunglah, aku ditolong oleh penjaga pantai.\",\n",
    "             \"Betusta tinggal hanya bersama ibunya yang miskin. Walaupun demikian, Betusta selalu ceria. Ia dan ibunya hanya memiliki dua ekor domba. Betusta rajin menggembalakan domba di tepi hutan. Setiap pagi, ibunya memasukkan sepotong roti dan sebuah tempat air kosong ke dalam tasnya.\",\n",
    "             \"Dahulu kala, di Jepang, hidup sepasang suami istri yang mempunyai sifat sangat berbeda. Oda, si suami, adalah pedagang yang baik hati, jujur, dan penyabar. Shino, istrinya, mempunyai sifat yang buruk. Shino suka menghina orang. Meski bertabiat buruk, Oda selalu sabar dan menyayangi istrinya.\",\n",
    "             \"Aku melihat daun kelapa bergoyang ditiup angin. Suara ombak menderu saling berkejaran. Aku dan adik bermain pasir. Sungguh senang hatiku\",\n",
    "             \"Hari Minggu, aku pergi ke rumah temanku, Ani. Rumah Ani terletak di Jalan Seroja Nomor 7. Ani mempunyai seorang adik bernama Ayu. Ayu bersekolah di TK Rahayu. Ibu Ani bekerja di rumah sakit. Ibunya bekerja sebagai perawat. Ayah Ani seorang guru. Beliau mengajar di SMP.\",\n",
    "             \"Ibunya hanya pedagang pecel, ayahnya seorang pegawai rendahan. Anak mereka kecil-kecil. Untuk menambah penghasilan ayahnya bila malam hari menjalankan becak tetangganya. Begitu berat bagi kaum miskin hidup di masa sulit seperti sekarang ini.\",\n",
    "             \"Hujan tak juga reda. Dengan suaranya yang khas ia manawarkan dagangannya agar langganannya keluar sejenak untuk menikmati bajigur dagangannya. Tetapi meskipun tekun ia belum pernah kaya. Hidupnya tetap sulit.\",\n",
    "             \"Gita seorang anak yang rajin. Setiap hari ia selalu membantu ibunya menyapu dan mencuci pakaian. Tidak pernah waktu luangnya digunakan untuk berpangku tangan. Suatu hari Gita diajak belanja ke pasar oleh ibunya. Ia begitu cekatan dalam membantu ibunya membawa belanjaan. Gita selalu mengatakan pada teman-temannya bahwa bekerja membantu orang tua adalah perbuatan mulia.\",\n",
    "             \"Semut merah itu berusaha naik ke atas daun melawan gelombang yang besar. Berkat ketabahannya, ia dapat mencapai permukaan daun itu dan berpegangan kuat-kuat di sana.\",\n",
    "             \"Linda seringkali kesulitan menuliskan ide-ide yang ada dalam pikirannya ke dalam bentuk karangan\",\n",
    "             \"Pak Suryana memandangi tanaman padinya yang menguning. Ada rasa bahagia menyelinap di hatinya. 'Semoga panen tahun ini hasilnya melimpah.' Gumamnya  sambil  memegang  tangkai  padi.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = document1\n",
    "len(document)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"saya sedang asik-asiknya makan\",\n",
    "\"lagi dengerin musik sambil minum air\",\n",
    "\"ketika disana, dia masih minum air\",\n",
    "\"aku mau pergi ke bandung\",\n",
    "\"habis ini aku langsung pergi ke luar\",\n",
    "\"waktu telah menunjukkan jam segini\",\n",
    "\"Ia ingin pergi mencari obat dengan berjalan\",\n",
    "\"Aku segera melakukan\",\n",
    "\"Tak disangka ternyata Andi membalasnya\",\n",
    "\"Pergi untuk kembali\",\n",
    "\"Toni masih mau memboncengkan Andi hingga sampai rumah\",\n",
    "\"Aku mau menyelesaikan tugaas\",\n",
    "\"Bel telah berbunyi sebagai tanda\",\n",
    "\"Perutnya terasa sangat lapar\",\n",
    "\"Budi lebih cerdas daripada Anton\",\n",
    "\"Anton menyuruh pembantunya agar lari\",\n",
    "\"Budi berpikir bahwa itu adalah bohong\",\n",
    "\"Jika nanti jadi pergi ke sana\",\n",
    "\"Dia terbayang kejadian yang dialami tadi pagi\",\n",
    "\"Hal itu sudah biasa dilakukan\",\n",
    "\"Dengan kekayaan itu\",\n",
    "\"Santo selalu membersihkan selokan\",\n",
    "\"Dengan penuh kesabaran\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from preprocess.normalize import Normalize\n",
    "from preprocess.tokenize import Tokenize\n",
    "from preprocess.symspell import SymSpell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionary...\n",
      "Processing dictionary...\n",
      "Copied 94811 words to master dictionary...\n",
      "Copied 679534 hashes to master dictionary...\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "normalizer = Normalize()\n",
    "tokenizer = Tokenize()\n",
    "symspell = SymSpell(max_dictionary_edit_distance=3)\n",
    "symspell.load_complete_model_from_json('preprocess\\data\\corpus_complete_model.json', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do process\n",
    "doc_preprocessed = []\n",
    "\n",
    "for tweet in document:\n",
    "    # normalize\n",
    "    tweet_norm = normalizer.remove_ascii_unicode(tweet)\n",
    "    tweet_norm = normalizer.remove_rt_fav(tweet_norm)\n",
    "    tweet_norm = normalizer.lower_text(tweet_norm)\n",
    "    tweet_norm = normalizer.remove_newline(tweet_norm)\n",
    "    tweet_norm = normalizer.remove_url(tweet_norm)\n",
    "    tweet_norm = normalizer.remove_emoticon(tweet_norm)\n",
    "    tweet_norm = normalizer.remove_hashtag_mention(tweet_norm)\n",
    "    tweet_norm = normalizer.remove_punctuation(tweet_norm)\n",
    "    \n",
    "    # tokenize\n",
    "    tweet_tok = tokenizer.WordTokenize(tweet_norm, removepunct=True)\n",
    "    \n",
    "    # spell correction\n",
    "    temp = []\n",
    "    for token in tweet_tok:\n",
    "        suggestion = symspell.lookup(phrase=token, verbosity=1, max_edit_distance=3)\n",
    "\n",
    "        # option if there is no suggestion\n",
    "        if len(suggestion) > 0:\n",
    "            get_suggestion = str(suggestion[0]).split(':')[0]\n",
    "            temp.append(get_suggestion)\n",
    "        else:\n",
    "            temp.append(token)\n",
    "    tweet_prepared = ' '.join(temp)\n",
    "    \n",
    "    doc_preprocessed.append(tweet_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bu siti seorang pembuat kue yang sukses segala jenis kue yang dibuatnya rasanya enak dan laris manis ketika dijual',\n",
       " 'anak kembar yang masih duduk di bangku sekolah dasar itu memiliki sifat yang berlawanan roda salah satu dari anak kembar itu sangat baik dan rajin membantu orang tuanya bekerja di pasar sementara ironi sepanjang hari kerjanya hanya bermain ponsel ia juga sering memaksa orang tuanya untuk membelikan pulsa dan menuruti semua kebingungannya',\n",
       " 'keluarga mandi sangat baik mereka tinggal di desa sumasi setiap ada tetangga yang kesulitan mereka selalu membantunya dengan ikhlas mereka tidak pernah mengharapkan balas budi dari tetangga-tetangga yang pernah mereka bantu hari sabtu kami pergi ke pantai di sana kami melihat ombak besar yang mana ombak itu menerjang kami yang sedang berada di pinggir pantai aku terempas ombak hingga ke tengah laut untunglah aku ditolong oleh penjaga pantai',\n",
       " 'bequest tinggal hanya bersama ibunya yang miskin walaupun demikian bequest selalu ceria ia dan ibunya hanya memiliki dua ekor domba bequest rajin menggembalakan domba di tepi hutan setiap pagi ibunya memasukkan sepotong roti dan sebuah tempat air kosong ke dalam tasnya',\n",
       " 'dahulu kala di jepang hidup sepasang suami istri yang mempunyai sifat sangat berbeda roda si suami adalah pedagang yang baik hati jujur dan penyabar sini istrinya mempunyai sifat yang buruk sini suka menghina orang meski bertabiat buruk roda selalu sabar dan menyayangi istrinya',\n",
       " 'aku melihat daun kelapa bergoyang ditiup angin suara ombak menderu saling berkejaran aku dan adik bermain pasir sungguh senang haiku',\n",
       " 'hari minggu aku pergi ke rumah temanku ani rumah ani terletak di jalan seroja nomor 7 ani mempunyai seorang adik bernama ayu ayu bersekolah di tk rahayu ibu ani bekerja di rumah sakit ibunya bekerja sebagai perawat ayah ani seorang guru beliau mengajar di smp',\n",
       " 'ibunya hanya pedagang pecel ayahnya seorang pegawai rendahan anak mereka kecil-kecil untuk menambah penghasilan ayahnya bila malam hari menjalankan becak tetangganya begitu berat bagi kaum miskin hidup di masa sulit seperti sekarang ini',\n",
       " 'hujan tak juga reda dengan suaranya yang khas ia menawarkan undangannya agar langganannya keluar sejenak untuk menikmati bajigur undangannya tetapi meskipun tekun ia belum pernah kaya hidupnya tetap sulit',\n",
       " 'gita seorang anak yang rajin setiap hari ia selalu membantu ibunya menyapu dan mencuci pakaian tidak pernah waktu uangnya digunakan untuk berpangku tangan suatu hari gita diajak belanja ke pasar oleh ibunya ia begitu cekatan dalam membantu ibunya membawa belanjaan gita selalu mengatakan pada teman-temannya bahwa bekerja membantu orang tua adalah perbuatan mulia',\n",
       " 'semut merah itu berusaha naik ke atas daun melawan gelombang yang besar berkat kemarahannya ia dapat mencapai permukaan daun itu dan berpegangan kuat-kuat di sana',\n",
       " 'linda seringkali kesulitan menuliskan bedside yang ada dalam pikirannya ke dalam bentuk karangan',\n",
       " 'pak durjana memandangi tanaman jadinya yang menguning ada rasa bahagia menyelinap di hatinya semoga panen tahun ini hasilnya melimpah rumahnya sambil memegang tangkai padi']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSLDA\n",
    "## HMM Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from hmmtagger.tagger import MainTagger\n",
    "from tokenization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "tagger = MainTagger(\"resource/Lexicon.trn\", \"resource/Ngram.trn\", 0, 3, 3, 0, 0, False, 0.2, 0, 500.0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do process\n",
    "doc_tagged = []\n",
    "\n",
    "for tweet in doc_preprocessed:\n",
    "    if len(tweet) == 0: continue\n",
    "    out = sentence_extraction(cleaning(tweet))\n",
    "\n",
    "    join_token = []\n",
    "    for o in out:\n",
    "        strtag = \" \".join(tokenisasi_kalimat(o)).strip()\n",
    "        join_token.extend(tagger.taggingStr(strtag))\n",
    "    doc_tagged.append(' '.join(join_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bu/NN siti/NN seorang/NN pembuat/NN kue/NN yang/SC sukses/NN segala/RB jenis/NN kue/NN yang/SC dibuatnya/VBT rasanya/NN enak/NN dan/CC laris/JJ manis/JJ ketika/SC dijual/VBT\n",
      "anak/NN kembar/NN yang/SC masih/RB duduk/VBI di/IN bangku/NN sekolah/NN dasar/NN itu/DT memiliki/VBT sifat/NN yang/SC berlawanan/VBT roda/NN salah/JJ satu/CDP dari/IN anak/NN kembar/NN itu/DT sangat/RB baik/JJ dan/CC rajin/NN membantu/VBT orang/NN tuanya/NN bekerja/VBI di/IN pasar/NN sementara/JJ ironi/NN sepanjang/RB hari/NN kerjanya/NN hanya/RB bermain/JJ ponsel/NN ia/PRP juga/RB sering/JJ memaksa/VBT orang/NN tuanya/NN untuk/IN membelikan/VBT pulsa/NN dan/CC menuruti/VBT semua/CDI kebingungannya/NN\n",
      "keluarga/NN mandi/NN sangat/RB baik/JJ mereka/PRP tinggal/VBI di/IN desa/NN sumasi/NN setiap/DT ada/VBI tetangga/NN yang/SC kesulitan/NN mereka/PRP selalu/RB membantunya/VBT dengan/IN ikhlas/JJ mereka/PRP tidak/NEG pernah/RB mengharapkan/VBI balas/NN budi/NN dari/IN tetangga-tetangga/NN yang/SC pernah/RB mereka/PRP bantu/VBI hari/NN sabtu/NN kami/PRP pergi/VBI ke/IN pantai/NN di/IN sana/PRL kami/PRP melihat/VBT ombak/NN besar/JJ yang/SC mana/NN ombak/NN itu/DT menerjang/VBT kami/PRP yang/SC sedang/RB berada/VBI di/IN pinggir/NN pantai/NN aku/NN terempas/NN ombak/NN hingga/CC ke/IN tengah/NN laut/NN untunglah/IN aku/NN ditolong/VBT oleh/IN penjaga/NN pantai/NN\n",
      "bequest/NN tinggal/VBI hanya/RB bersama/IN ibunya/NN yang/SC miskin/NN walaupun/CC demikian/DT bequest/NN selalu/RB ceria/JJ ia/PRP dan/CC ibunya/NN hanya/RB memiliki/VBT dua/CDP ekor/NN domba/NN bequest/NN rajin/NN menggembalakan/VBT domba/NN di/IN tepi/RB hutan/NN setiap/DT pagi/NN ibunya/NN memasukkan/VBT sepotong/IN roti/NN dan/CC sebuah/NN tempat/NN air/NN kosong/JJ ke/IN dalam/IN tasnya/NN\n",
      "dahulu/JJ kala/NN di/IN jepang/NN hidup/NN sepasang/NN suami/NN istri/NN yang/SC mempunyai/VBT sifat/NN sangat/RB berbeda/JJ roda/NN si/RP suami/NN adalah/VBT pedagang/NN yang/SC baik/JJ hati/NN jujur/JJ dan/CC penyabar/NN sini/PRL istrinya/NN mempunyai/VBT sifat/NN yang/SC buruk/JJ sini/PRL suka/VBI menghina/VBT orang/NN meski/SC bertabiat/VBI buruk/JJ roda/NN selalu/RB sabar/NN dan/CC menyayangi/VBT istrinya/NN\n",
      "aku/NN melihat/VBT daun/NN kelapa/NN bergoyang/VBI ditiup/VBT angin/NN suara/NN ombak/NN menderu/VBT saling/RB berkejaran/VBT aku/NN dan/CC adik/NNP bermain/JJ pasir/NN sungguh/RB senang/JJ haiku/NN\n",
      "hari/NN minggu/NN aku/NN pergi/VBI ke/IN rumah/NN temanku/NN ani/NN rumah/NN ani/NN terletak/VBI di/IN jalan/NN seroja/NN nomor/NN 7/CDP ani/NN mempunyai/VBT seorang/NN adik/NNP bernama/VBT ayu/NN ayu/NN bersekolah/VBI di/IN tk/NN rahayu/JJ ibu/NNP ani/NN bekerja/VBI di/IN rumah/NN sakit/JJ ibunya/NN bekerja/VBI sebagai/IN perawat/NN ayah/NN ani/NN seorang/NN guru/NN beliau/NN mengajar/VBT di/IN smp/NN\n",
      "ibunya/NN hanya/RB pedagang/NN pecel/NN ayahnya/NN seorang/NN pegawai/NN rendahan/JJ anak/NN mereka/PRP kecil-kecil/JJ untuk/IN menambah/VBT penghasilan/NN ayahnya/NN bila/SC malam/NN hari/NN menjalankan/VBT becak/NN tetangganya/NNG begitu/RB berat/JJ bagi/IN kaum/NN miskin/NN hidup/VBI di/IN masa/NN sulit/JJ seperti/IN sekarang/NN ini/DT\n",
      "hujan/NN tak/NEG juga/RB reda/JJ dengan/IN suaranya/NN yang/SC khas/JJ ia/PRP menawarkan/VBT undangannya/NN agar/IN langganannya/NN keluar/VBI sejenak/IN untuk/IN menikmati/VBT bajigur/NN undangannya/NN tetapi/CC meskipun/CC tekun/NN ia/PRP belum/NEG pernah/RB kaya/JJ hidupnya/NN tetap/JJ sulit/JJ\n",
      "gita/NN seorang/NN anak/NN yang/SC rajin/NN setiap/DT hari/NN ia/PRP selalu/RB membantu/VBT ibunya/NN menyapu/VBT dan/CC mencuci/VBT pakaian/NN tidak/NEG pernah/RB waktu/NN uangnya/NN digunakan/VBT untuk/IN berpangku/VBT tangan/NN suatu/DT hari/NN gita/NN diajak/VBT belanja/NN ke/IN pasar/NN oleh/IN ibunya/NN ia/PRP begitu/RB cekatan/JJ dalam/IN membantu/VBT ibunya/NN membawa/VBT belanjaan/NN gita/NN selalu/RB mengatakan/VBI pada/IN teman-temannya/NN bahwa/SC bekerja/VBI membantu/VBT orang/NN tua/JJ adalah/VBT perbuatan/NN mulia/NN\n",
      "semut/NN merah/VBT itu/DT berusaha/VBI naik/VBI ke/IN atas/IN daun/NN melawan/VBT gelombang/NN yang/SC besar/JJ berkat/NN kemarahannya/NN ia/PRP dapat/MD mencapai/VBT permukaan/NN daun/NN itu/DT dan/CC berpegangan/VBT kuat-kuat/NN di/IN sana/PRL\n",
      "linda/NN seringkali/JJ kesulitan/NN menuliskan/VBT bedside/NN yang/SC ada/VBI dalam/IN pikirannya/NN ke/IN dalam/IN bentuk/NN karangan/NN\n",
      "pak/NN durjana/NN memandangi/VBT tanaman/NN jadinya/NN yang/SC menguning/VBT ada/VBI rasa/NN bahagia/NN menyelinap/VBT di/IN hatinya/NN semoga/RB panen/NN tahun/NN ini/DT hasilnya/NNG melimpah/VBT rumahnya/NN sambil/SC memegang/VBT tangkai/NN padi/NN\n"
     ]
    }
   ],
   "source": [
    "for _ in doc_tagged:\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kelas Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define\n",
    "Ccon = ['JJ', 'NN','NNP', 'NNG', 'VBI', 'VBT']\n",
    "Cfnc = ['OP', 'CP', 'GM', ';', ':', '\"', '.',\n",
    "         ',', '-', '...', 'RB', 'IN', 'MD', 'CC',\n",
    "         'SC', 'DT', 'UH', 'CDO', 'CDC', 'CDP', 'CDI',\n",
    "         'PRP', 'WP', 'PRN', 'PRL', 'NEG', 'SYM', 'RP', 'FW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do process\n",
    "doc_classified = []\n",
    "\n",
    "for tweet in doc_tagged:\n",
    "    tweet_split = tweet.split(' ')\n",
    "    \n",
    "    temp = {\"Content\": [], \"Function\": []}\n",
    "    con = []\n",
    "    fnc = []\n",
    "    \n",
    "    for token in tweet_split:\n",
    "        word = token.split('/', 1)[0]\n",
    "        tag = token.split('/', 1)[1]\n",
    "        \n",
    "        if tag in Ccon:\n",
    "            con.append(token)\n",
    "        elif tag in Cfnc:\n",
    "            fnc.append(token)\n",
    "            \n",
    "    temp[\"Content\"].append(' '.join(con))\n",
    "    temp[\"Function\"].append(' '.join(fnc))\n",
    "    \n",
    "    doc_classified.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Content': ['bu/NN siti/NN seorang/NN pembuat/NN kue/NN sukses/NN jenis/NN kue/NN dibuatnya/VBT rasanya/NN enak/NN laris/JJ manis/JJ dijual/VBT'],\n",
       "  'Function': ['yang/SC segala/RB yang/SC dan/CC ketika/SC']},\n",
       " {'Content': ['anak/NN kembar/NN duduk/VBI bangku/NN sekolah/NN dasar/NN memiliki/VBT sifat/NN berlawanan/VBT roda/NN salah/JJ anak/NN kembar/NN baik/JJ rajin/NN membantu/VBT orang/NN tuanya/NN bekerja/VBI pasar/NN sementara/JJ ironi/NN hari/NN kerjanya/NN bermain/JJ ponsel/NN sering/JJ memaksa/VBT orang/NN tuanya/NN membelikan/VBT pulsa/NN menuruti/VBT kebingungannya/NN'],\n",
       "  'Function': ['yang/SC masih/RB di/IN itu/DT yang/SC satu/CDP dari/IN itu/DT sangat/RB dan/CC di/IN sepanjang/RB hanya/RB ia/PRP juga/RB untuk/IN dan/CC semua/CDI']},\n",
       " {'Content': ['keluarga/NN mandi/NN baik/JJ tinggal/VBI desa/NN sumasi/NN ada/VBI tetangga/NN kesulitan/NN membantunya/VBT ikhlas/JJ mengharapkan/VBI balas/NN budi/NN tetangga-tetangga/NN bantu/VBI hari/NN sabtu/NN pergi/VBI pantai/NN melihat/VBT ombak/NN besar/JJ mana/NN ombak/NN menerjang/VBT berada/VBI pinggir/NN pantai/NN aku/NN terempas/NN ombak/NN tengah/NN laut/NN aku/NN ditolong/VBT penjaga/NN pantai/NN'],\n",
       "  'Function': ['sangat/RB mereka/PRP di/IN setiap/DT yang/SC mereka/PRP selalu/RB dengan/IN mereka/PRP tidak/NEG pernah/RB dari/IN yang/SC pernah/RB mereka/PRP kami/PRP ke/IN di/IN sana/PRL kami/PRP yang/SC itu/DT kami/PRP yang/SC sedang/RB di/IN hingga/CC ke/IN untunglah/IN oleh/IN']},\n",
       " {'Content': ['bequest/NN tinggal/VBI ibunya/NN miskin/NN bequest/NN ceria/JJ ibunya/NN memiliki/VBT ekor/NN domba/NN bequest/NN rajin/NN menggembalakan/VBT domba/NN hutan/NN pagi/NN ibunya/NN memasukkan/VBT roti/NN sebuah/NN tempat/NN air/NN kosong/JJ tasnya/NN'],\n",
       "  'Function': ['hanya/RB bersama/IN yang/SC walaupun/CC demikian/DT selalu/RB ia/PRP dan/CC hanya/RB dua/CDP di/IN tepi/RB setiap/DT sepotong/IN dan/CC ke/IN dalam/IN']},\n",
       " {'Content': ['dahulu/JJ kala/NN jepang/NN hidup/NN sepasang/NN suami/NN istri/NN mempunyai/VBT sifat/NN berbeda/JJ roda/NN suami/NN adalah/VBT pedagang/NN baik/JJ hati/NN jujur/JJ penyabar/NN istrinya/NN mempunyai/VBT sifat/NN buruk/JJ suka/VBI menghina/VBT orang/NN bertabiat/VBI buruk/JJ roda/NN sabar/NN menyayangi/VBT istrinya/NN'],\n",
       "  'Function': ['di/IN yang/SC sangat/RB si/RP yang/SC dan/CC sini/PRL yang/SC sini/PRL meski/SC selalu/RB dan/CC']},\n",
       " {'Content': ['aku/NN melihat/VBT daun/NN kelapa/NN bergoyang/VBI ditiup/VBT angin/NN suara/NN ombak/NN menderu/VBT berkejaran/VBT aku/NN adik/NNP bermain/JJ pasir/NN senang/JJ haiku/NN'],\n",
       "  'Function': ['saling/RB dan/CC sungguh/RB']},\n",
       " {'Content': ['hari/NN minggu/NN aku/NN pergi/VBI rumah/NN temanku/NN ani/NN rumah/NN ani/NN terletak/VBI jalan/NN seroja/NN nomor/NN ani/NN mempunyai/VBT seorang/NN adik/NNP bernama/VBT ayu/NN ayu/NN bersekolah/VBI tk/NN rahayu/JJ ibu/NNP ani/NN bekerja/VBI rumah/NN sakit/JJ ibunya/NN bekerja/VBI perawat/NN ayah/NN ani/NN seorang/NN guru/NN beliau/NN mengajar/VBT smp/NN'],\n",
       "  'Function': ['ke/IN di/IN 7/CDP di/IN di/IN sebagai/IN di/IN']},\n",
       " {'Content': ['ibunya/NN pedagang/NN pecel/NN ayahnya/NN seorang/NN pegawai/NN rendahan/JJ anak/NN kecil-kecil/JJ menambah/VBT penghasilan/NN ayahnya/NN malam/NN hari/NN menjalankan/VBT becak/NN tetangganya/NNG berat/JJ kaum/NN miskin/NN hidup/VBI masa/NN sulit/JJ sekarang/NN'],\n",
       "  'Function': ['hanya/RB mereka/PRP untuk/IN bila/SC begitu/RB bagi/IN di/IN seperti/IN ini/DT']},\n",
       " {'Content': ['hujan/NN reda/JJ suaranya/NN khas/JJ menawarkan/VBT undangannya/NN langganannya/NN keluar/VBI menikmati/VBT bajigur/NN undangannya/NN tekun/NN kaya/JJ hidupnya/NN tetap/JJ sulit/JJ'],\n",
       "  'Function': ['tak/NEG juga/RB dengan/IN yang/SC ia/PRP agar/IN sejenak/IN untuk/IN tetapi/CC meskipun/CC ia/PRP belum/NEG pernah/RB']},\n",
       " {'Content': ['gita/NN seorang/NN anak/NN rajin/NN hari/NN membantu/VBT ibunya/NN menyapu/VBT mencuci/VBT pakaian/NN waktu/NN uangnya/NN digunakan/VBT berpangku/VBT tangan/NN hari/NN gita/NN diajak/VBT belanja/NN pasar/NN ibunya/NN cekatan/JJ membantu/VBT ibunya/NN membawa/VBT belanjaan/NN gita/NN mengatakan/VBI teman-temannya/NN bekerja/VBI membantu/VBT orang/NN tua/JJ adalah/VBT perbuatan/NN mulia/NN'],\n",
       "  'Function': ['yang/SC setiap/DT ia/PRP selalu/RB dan/CC tidak/NEG pernah/RB untuk/IN suatu/DT ke/IN oleh/IN ia/PRP begitu/RB dalam/IN selalu/RB pada/IN bahwa/SC']},\n",
       " {'Content': ['semut/NN merah/VBT berusaha/VBI naik/VBI daun/NN melawan/VBT gelombang/NN besar/JJ berkat/NN kemarahannya/NN mencapai/VBT permukaan/NN daun/NN berpegangan/VBT kuat-kuat/NN'],\n",
       "  'Function': ['itu/DT ke/IN atas/IN yang/SC ia/PRP dapat/MD itu/DT dan/CC di/IN sana/PRL']},\n",
       " {'Content': ['linda/NN seringkali/JJ kesulitan/NN menuliskan/VBT bedside/NN ada/VBI pikirannya/NN bentuk/NN karangan/NN'],\n",
       "  'Function': ['yang/SC dalam/IN ke/IN dalam/IN']},\n",
       " {'Content': ['pak/NN durjana/NN memandangi/VBT tanaman/NN jadinya/NN menguning/VBT ada/VBI rasa/NN bahagia/NN menyelinap/VBT hatinya/NN panen/NN tahun/NN hasilnya/NNG melimpah/VBT rumahnya/NN memegang/VBT tangkai/NN padi/NN'],\n",
       "  'Function': ['yang/SC di/IN semoga/RB ini/DT sambil/SC']}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bu/NN siti/NN seorang/NN pembuat/NN kue/NN sukses/NN jenis/NN kue/NN dibuatnya/VBT rasanya/NN enak/NN laris/JJ manis/JJ dijual/VBT', 'anak/NN kembar/NN duduk/VBI bangku/NN sekolah/NN dasar/NN memiliki/VBT sifat/NN berlawanan/VBT roda/NN salah/JJ anak/NN kembar/NN baik/JJ rajin/NN membantu/VBT orang/NN tuanya/NN bekerja/VBI pasar/NN sementara/JJ ironi/NN hari/NN kerjanya/NN bermain/JJ ponsel/NN sering/JJ memaksa/VBT orang/NN tuanya/NN membelikan/VBT pulsa/NN menuruti/VBT kebingungannya/NN', 'keluarga/NN mandi/NN baik/JJ tinggal/VBI desa/NN sumasi/NN ada/VBI tetangga/NN kesulitan/NN membantunya/VBT ikhlas/JJ mengharapkan/VBI balas/NN budi/NN tetangga-tetangga/NN bantu/VBI hari/NN sabtu/NN pergi/VBI pantai/NN melihat/VBT ombak/NN besar/JJ mana/NN ombak/NN menerjang/VBT berada/VBI pinggir/NN pantai/NN aku/NN terempas/NN ombak/NN tengah/NN laut/NN aku/NN ditolong/VBT penjaga/NN pantai/NN', 'bequest/NN tinggal/VBI ibunya/NN miskin/NN bequest/NN ceria/JJ ibunya/NN memiliki/VBT ekor/NN domba/NN bequest/NN rajin/NN menggembalakan/VBT domba/NN hutan/NN pagi/NN ibunya/NN memasukkan/VBT roti/NN sebuah/NN tempat/NN air/NN kosong/JJ tasnya/NN', 'dahulu/JJ kala/NN jepang/NN hidup/NN sepasang/NN suami/NN istri/NN mempunyai/VBT sifat/NN berbeda/JJ roda/NN suami/NN adalah/VBT pedagang/NN baik/JJ hati/NN jujur/JJ penyabar/NN istrinya/NN mempunyai/VBT sifat/NN buruk/JJ suka/VBI menghina/VBT orang/NN bertabiat/VBI buruk/JJ roda/NN sabar/NN menyayangi/VBT istrinya/NN', 'aku/NN melihat/VBT daun/NN kelapa/NN bergoyang/VBI ditiup/VBT angin/NN suara/NN ombak/NN menderu/VBT berkejaran/VBT aku/NN adik/NNP bermain/JJ pasir/NN senang/JJ haiku/NN', 'hari/NN minggu/NN aku/NN pergi/VBI rumah/NN temanku/NN ani/NN rumah/NN ani/NN terletak/VBI jalan/NN seroja/NN nomor/NN ani/NN mempunyai/VBT seorang/NN adik/NNP bernama/VBT ayu/NN ayu/NN bersekolah/VBI tk/NN rahayu/JJ ibu/NNP ani/NN bekerja/VBI rumah/NN sakit/JJ ibunya/NN bekerja/VBI perawat/NN ayah/NN ani/NN seorang/NN guru/NN beliau/NN mengajar/VBT smp/NN', 'ibunya/NN pedagang/NN pecel/NN ayahnya/NN seorang/NN pegawai/NN rendahan/JJ anak/NN kecil-kecil/JJ menambah/VBT penghasilan/NN ayahnya/NN malam/NN hari/NN menjalankan/VBT becak/NN tetangganya/NNG berat/JJ kaum/NN miskin/NN hidup/VBI masa/NN sulit/JJ sekarang/NN', 'hujan/NN reda/JJ suaranya/NN khas/JJ menawarkan/VBT undangannya/NN langganannya/NN keluar/VBI menikmati/VBT bajigur/NN undangannya/NN tekun/NN kaya/JJ hidupnya/NN tetap/JJ sulit/JJ', 'gita/NN seorang/NN anak/NN rajin/NN hari/NN membantu/VBT ibunya/NN menyapu/VBT mencuci/VBT pakaian/NN waktu/NN uangnya/NN digunakan/VBT berpangku/VBT tangan/NN hari/NN gita/NN diajak/VBT belanja/NN pasar/NN ibunya/NN cekatan/JJ membantu/VBT ibunya/NN membawa/VBT belanjaan/NN gita/NN mengatakan/VBI teman-temannya/NN bekerja/VBI membantu/VBT orang/NN tua/JJ adalah/VBT perbuatan/NN mulia/NN', 'semut/NN merah/VBT berusaha/VBI naik/VBI daun/NN melawan/VBT gelombang/NN besar/JJ berkat/NN kemarahannya/NN mencapai/VBT permukaan/NN daun/NN berpegangan/VBT kuat-kuat/NN', 'linda/NN seringkali/JJ kesulitan/NN menuliskan/VBT bedside/NN ada/VBI pikirannya/NN bentuk/NN karangan/NN', 'pak/NN durjana/NN memandangi/VBT tanaman/NN jadinya/NN menguning/VBT ada/VBI rasa/NN bahagia/NN menyelinap/VBT hatinya/NN panen/NN tahun/NN hasilnya/NNG melimpah/VBT rumahnya/NN memegang/VBT tangkai/NN padi/NN']\n",
      "\n",
      "[['bu', 'siti', 'seorang', 'pembuat', 'kue', 'sukses', 'jenis', 'kue', 'dibuatnya', 'rasanya', 'enak', 'laris', 'manis', 'dijual'], ['anak', 'kembar', 'duduk', 'bangku', 'sekolah', 'dasar', 'memiliki', 'sifat', 'berlawanan', 'roda', 'salah', 'anak', 'kembar', 'baik', 'rajin', 'membantu', 'orang', 'tuanya', 'bekerja', 'pasar', 'sementara', 'ironi', 'hari', 'kerjanya', 'bermain', 'ponsel', 'sering', 'memaksa', 'orang', 'tuanya', 'membelikan', 'pulsa', 'menuruti', 'kebingungannya'], ['keluarga', 'mandi', 'baik', 'tinggal', 'desa', 'sumasi', 'ada', 'tetangga', 'kesulitan', 'membantunya', 'ikhlas', 'mengharapkan', 'balas', 'budi', 'tetangga-tetangga', 'bantu', 'hari', 'sabtu', 'pergi', 'pantai', 'melihat', 'ombak', 'besar', 'mana', 'ombak', 'menerjang', 'berada', 'pinggir', 'pantai', 'aku', 'terempas', 'ombak', 'tengah', 'laut', 'aku', 'ditolong', 'penjaga', 'pantai'], ['bequest', 'tinggal', 'ibunya', 'miskin', 'bequest', 'ceria', 'ibunya', 'memiliki', 'ekor', 'domba', 'bequest', 'rajin', 'menggembalakan', 'domba', 'hutan', 'pagi', 'ibunya', 'memasukkan', 'roti', 'sebuah', 'tempat', 'air', 'kosong', 'tasnya'], ['dahulu', 'kala', 'jepang', 'hidup', 'sepasang', 'suami', 'istri', 'mempunyai', 'sifat', 'berbeda', 'roda', 'suami', 'adalah', 'pedagang', 'baik', 'hati', 'jujur', 'penyabar', 'istrinya', 'mempunyai', 'sifat', 'buruk', 'suka', 'menghina', 'orang', 'bertabiat', 'buruk', 'roda', 'sabar', 'menyayangi', 'istrinya'], ['aku', 'melihat', 'daun', 'kelapa', 'bergoyang', 'ditiup', 'angin', 'suara', 'ombak', 'menderu', 'berkejaran', 'aku', 'adik', 'bermain', 'pasir', 'senang', 'haiku'], ['hari', 'minggu', 'aku', 'pergi', 'rumah', 'temanku', 'ani', 'rumah', 'ani', 'terletak', 'jalan', 'seroja', 'nomor', 'ani', 'mempunyai', 'seorang', 'adik', 'bernama', 'ayu', 'ayu', 'bersekolah', 'tk', 'rahayu', 'ibu', 'ani', 'bekerja', 'rumah', 'sakit', 'ibunya', 'bekerja', 'perawat', 'ayah', 'ani', 'seorang', 'guru', 'beliau', 'mengajar', 'smp'], ['ibunya', 'pedagang', 'pecel', 'ayahnya', 'seorang', 'pegawai', 'rendahan', 'anak', 'kecil-kecil', 'menambah', 'penghasilan', 'ayahnya', 'malam', 'hari', 'menjalankan', 'becak', 'tetangganya', 'berat', 'kaum', 'miskin', 'hidup', 'masa', 'sulit', 'sekarang'], ['hujan', 'reda', 'suaranya', 'khas', 'menawarkan', 'undangannya', 'langganannya', 'keluar', 'menikmati', 'bajigur', 'undangannya', 'tekun', 'kaya', 'hidupnya', 'tetap', 'sulit'], ['gita', 'seorang', 'anak', 'rajin', 'hari', 'membantu', 'ibunya', 'menyapu', 'mencuci', 'pakaian', 'waktu', 'uangnya', 'digunakan', 'berpangku', 'tangan', 'hari', 'gita', 'diajak', 'belanja', 'pasar', 'ibunya', 'cekatan', 'membantu', 'ibunya', 'membawa', 'belanjaan', 'gita', 'mengatakan', 'teman-temannya', 'bekerja', 'membantu', 'orang', 'tua', 'adalah', 'perbuatan', 'mulia'], ['semut', 'merah', 'berusaha', 'naik', 'daun', 'melawan', 'gelombang', 'besar', 'berkat', 'kemarahannya', 'mencapai', 'permukaan', 'daun', 'berpegangan', 'kuat-kuat'], ['linda', 'seringkali', 'kesulitan', 'menuliskan', 'bedside', 'ada', 'pikirannya', 'bentuk', 'karangan'], ['pak', 'durjana', 'memandangi', 'tanaman', 'jadinya', 'menguning', 'ada', 'rasa', 'bahagia', 'menyelinap', 'hatinya', 'panen', 'tahun', 'hasilnya', 'melimpah', 'rumahnya', 'memegang', 'tangkai', 'padi']]\n"
     ]
    }
   ],
   "source": [
    "# split document content and function\n",
    "doc_content = []\n",
    "for tweet in doc_classified:\n",
    "    doc_content.append(''.join(tweet['Content']))\n",
    "\n",
    "print(doc_content)\n",
    "print()\n",
    "\n",
    "# split tag and word\n",
    "doc_prepared = []\n",
    "for tweet in doc_content:\n",
    "    tweet_split = tweet.split(' ')\n",
    "    \n",
    "    temp = []\n",
    "    for token in tweet_split:\n",
    "        word = token.split('/', 1)[0]\n",
    "        temp.append(word)\n",
    "    \n",
    "    doc_prepared.append(temp)\n",
    "\n",
    "print(doc_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from lda.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "Wall time: 8.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# iniatialize\n",
    "k = 3\n",
    "alpha = 0.01\n",
    "beta = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# do process\n",
    "lda = LdaModel(doc_prepared, k, alpha, beta, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lda.get_topic_word_pwz(doc_content)\n",
    "\n",
    "df_lda = pd.DataFrame(result, columns=['Topik', 'Kata', 'PWZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topik</th>\n",
       "      <th>Kata</th>\n",
       "      <th>PWZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ibunya/NN</td>\n",
       "      <td>0.062432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>hari/NN</td>\n",
       "      <td>0.046843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>seorang/NN</td>\n",
       "      <td>0.039049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>ani/NN</td>\n",
       "      <td>0.039049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>bekerja/VBI</td>\n",
       "      <td>0.031255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>membantu/VBT</td>\n",
       "      <td>0.031255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>bequest/NN</td>\n",
       "      <td>0.023461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>rajin/NN</td>\n",
       "      <td>0.023461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>rumah/NN</td>\n",
       "      <td>0.023461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>gita/NN</td>\n",
       "      <td>0.023461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>memiliki/VBT</td>\n",
       "      <td>0.015666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>domba/NN</td>\n",
       "      <td>0.015666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>ayu/NN</td>\n",
       "      <td>0.015666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>pasar/NN</td>\n",
       "      <td>0.015666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>miskin/NN</td>\n",
       "      <td>0.015666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>aku/NN</td>\n",
       "      <td>0.051490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>ombak/NN</td>\n",
       "      <td>0.041213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>ada/VBI</td>\n",
       "      <td>0.030935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>pantai/NN</td>\n",
       "      <td>0.030935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>daun/NN</td>\n",
       "      <td>0.030935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>besar/JJ</td>\n",
       "      <td>0.020658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>kesulitan/NN</td>\n",
       "      <td>0.020658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>pergi/VBI</td>\n",
       "      <td>0.020658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>melihat/VBT</td>\n",
       "      <td>0.020658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>ikhlas/JJ</td>\n",
       "      <td>0.010380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>berada/VBI</td>\n",
       "      <td>0.010380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>tengah/NN</td>\n",
       "      <td>0.010380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>baik/JJ</td>\n",
       "      <td>0.010380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>angin/NN</td>\n",
       "      <td>0.010380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>menderu/VBT</td>\n",
       "      <td>0.010380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>anak/NN</td>\n",
       "      <td>0.041641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>orang/NN</td>\n",
       "      <td>0.041641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>sifat/NN</td>\n",
       "      <td>0.031256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>roda/NN</td>\n",
       "      <td>0.031256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>baik/JJ</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>suami/NN</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>mempunyai/VBT</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>pedagang/NN</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>istrinya/NN</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>buruk/JJ</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>hidup/NN</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>hidup/VBI</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>sulit/JJ</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>adalah/VBT</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>undangannya/NN</td>\n",
       "      <td>0.020872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topik            Kata       PWZ\n",
       "0       0       ibunya/NN  0.062432\n",
       "1       0         hari/NN  0.046843\n",
       "2       0      seorang/NN  0.039049\n",
       "3       0          ani/NN  0.039049\n",
       "4       0     bekerja/VBI  0.031255\n",
       "5       0    membantu/VBT  0.031255\n",
       "6       0      bequest/NN  0.023461\n",
       "7       0        rajin/NN  0.023461\n",
       "8       0        rumah/NN  0.023461\n",
       "9       0         gita/NN  0.023461\n",
       "10      0    memiliki/VBT  0.015666\n",
       "11      0        domba/NN  0.015666\n",
       "12      0          ayu/NN  0.015666\n",
       "13      0        pasar/NN  0.015666\n",
       "14      0       miskin/NN  0.015666\n",
       "15      1          aku/NN  0.051490\n",
       "16      1        ombak/NN  0.041213\n",
       "17      1         ada/VBI  0.030935\n",
       "18      1       pantai/NN  0.030935\n",
       "19      1         daun/NN  0.030935\n",
       "20      1        besar/JJ  0.020658\n",
       "21      1    kesulitan/NN  0.020658\n",
       "22      1       pergi/VBI  0.020658\n",
       "23      1     melihat/VBT  0.020658\n",
       "24      1       ikhlas/JJ  0.010380\n",
       "25      1      berada/VBI  0.010380\n",
       "26      1       tengah/NN  0.010380\n",
       "27      1         baik/JJ  0.010380\n",
       "28      1        angin/NN  0.010380\n",
       "29      1     menderu/VBT  0.010380\n",
       "30      2         anak/NN  0.041641\n",
       "31      2        orang/NN  0.041641\n",
       "32      2        sifat/NN  0.031256\n",
       "33      2         roda/NN  0.031256\n",
       "34      2         baik/JJ  0.020872\n",
       "35      2        suami/NN  0.020872\n",
       "36      2   mempunyai/VBT  0.020872\n",
       "37      2     pedagang/NN  0.020872\n",
       "38      2     istrinya/NN  0.020872\n",
       "39      2        buruk/JJ  0.020872\n",
       "40      2        hidup/NN  0.020872\n",
       "41      2       hidup/VBI  0.020872\n",
       "42      2        sulit/JJ  0.020872\n",
       "43      2      adalah/VBT  0.020872\n",
       "44      2  undangannya/NN  0.020872"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.062432\n",
      "0.046843\n",
      "0.039049\n",
      "0.039049\n",
      "0.031255\n",
      "0.031255\n",
      "0.023461\n",
      "0.023461\n",
      "0.023461\n",
      "0.023461\n",
      "0.015666\n",
      "0.015666\n",
      "0.015666\n",
      "0.015666\n",
      "0.015666\n"
     ]
    }
   ],
   "source": [
    "print(df_lda[df_lda['Topik']==0]['PWZ'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.875847310257886"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.perplexity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dict_ldapwz = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_lda.iterrows():\n",
    "#     dict_ldapwz[row['Topik']].append(row['Kata'])\n",
    "    dict_ldapwz[row['Topik']].append([row['Kata'], row['PWZ']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [['ibunya/NN', 0.06243180046765393],\n",
       "  ['hari/NN', 0.04684333593141075],\n",
       "  ['seorang/NN', 0.03904910366328916],\n",
       "  ['ani/NN', 0.03904910366328916],\n",
       "  ['bekerja/VBI', 0.03125487139516757],\n",
       "  ['membantu/VBT', 0.03125487139516757],\n",
       "  ['bequest/NN', 0.023460639127045983],\n",
       "  ['rajin/NN', 0.023460639127045983],\n",
       "  ['rumah/NN', 0.023460639127045983],\n",
       "  ['gita/NN', 0.023460639127045983],\n",
       "  ['memiliki/VBT', 0.015666406858924394],\n",
       "  ['domba/NN', 0.015666406858924394],\n",
       "  ['ayu/NN', 0.015666406858924394],\n",
       "  ['pasar/NN', 0.015666406858924394],\n",
       "  ['miskin/NN', 0.015666406858924394]],\n",
       " 1: [['aku/NN', 0.05149023638232271],\n",
       "  ['ombak/NN', 0.041212744090441934],\n",
       "  ['ada/VBI', 0.030935251798561148],\n",
       "  ['pantai/NN', 0.030935251798561148],\n",
       "  ['daun/NN', 0.030935251798561148],\n",
       "  ['besar/JJ', 0.02065775950668037],\n",
       "  ['kesulitan/NN', 0.02065775950668037],\n",
       "  ['pergi/VBI', 0.02065775950668037],\n",
       "  ['melihat/VBT', 0.02065775950668037],\n",
       "  ['ikhlas/JJ', 0.01038026721479959],\n",
       "  ['berada/VBI', 0.01038026721479959],\n",
       "  ['tengah/NN', 0.01038026721479959],\n",
       "  ['baik/JJ', 0.01038026721479959],\n",
       "  ['angin/NN', 0.01038026721479959],\n",
       "  ['menderu/VBT', 0.01038026721479959]],\n",
       " 2: [['anak/NN', 0.04164070612668743],\n",
       "  ['orang/NN', 0.04164070612668743],\n",
       "  ['sifat/NN', 0.031256490134994805],\n",
       "  ['roda/NN', 0.031256490134994805],\n",
       "  ['baik/JJ', 0.02087227414330218],\n",
       "  ['suami/NN', 0.02087227414330218],\n",
       "  ['mempunyai/VBT', 0.02087227414330218],\n",
       "  ['pedagang/NN', 0.02087227414330218],\n",
       "  ['istrinya/NN', 0.02087227414330218],\n",
       "  ['buruk/JJ', 0.02087227414330218],\n",
       "  ['hidup/NN', 0.02087227414330218],\n",
       "  ['hidup/VBI', 0.02087227414330218],\n",
       "  ['sulit/JJ', 0.02087227414330218],\n",
       "  ['adalah/VBT', 0.02087227414330218],\n",
       "  ['undangannya/NN', 0.02087227414330218]]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(dict_ldapwz)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_grammar = \"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> NN | NN NN | NN JJ | NNG | NNP |  NP PP |\n",
    "    VP -> VBT NN | VBT NN NN | VBT NN CC NN | VBT NP | VBI | JJ\n",
    "    PP -> IN NP\n",
    "    IN -> 'di'\n",
    "    VBT -> 'memiliki', 'adalah', 'merupakan', 'terdapat', 'yaitu', 'sebagai', 'mempunyai'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP = ['_NN', '_NNG', '_NNP']\n",
    "VP = ['_VBT _NN', '_MD _VBT _NN', '_VBT _NN _DT', '_VBT _NN _SC _JJ', '_VBT _NN _JJ', '_RB _VBT _NP', '_VBT _RB _JJ', '_VBT _NN _NN', '_SC _VBT _NP', '_VBI', '_JJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_tag(dict_words_by_tag):\n",
    "    result = []\n",
    "    for key in dict_words_by_tag:\n",
    "        result.append(key)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_grammar(list_tag):\n",
    "    result = {}\n",
    "    \n",
    "    if '_VBT' not in list_tag:\n",
    "        list_tag.append('_VBT')\n",
    "    \n",
    "    if '_VBI' not in list_tag:\n",
    "        list_tag.append('_VBI')\n",
    "#     print(list_tag)\n",
    "    S = {\"_S\": [\"_NP _VP\"]}\n",
    "    PP = {\"_PP\": [\"_IN _NP\"]}\n",
    "    \n",
    "    if '_JJ' in list_tag:\n",
    "        NP_RULES = generate_NP(list_tag)\n",
    "        NP = {\"_NP\": NP_RULES}\n",
    "        if check_VP(list_tag):\n",
    "            VP_RULES = ['_JJ'] + generate_VP(list_tag)\n",
    "            VP = {\"_VP\": VP_RULES}\n",
    "        else:\n",
    "            VP = {\"_VP\": ['_JJ', '_PP']}\n",
    "\n",
    "        for r in [S, NP, VP, PP]:\n",
    "            result.update(r)\n",
    "        return result\n",
    "    else:\n",
    "        NP_RULES = remove_JJ(generate_NP(list_tag))\n",
    "        NP = {\"_NP\": NP_RULES}\n",
    "        if check_VP(list_tag):\n",
    "            VP_RULES = remove_JJ(generate_VP(list_tag))\n",
    "            VP = {\"_VP\": VP_RULES}\n",
    "        else:\n",
    "            VP = {\"_VP\": ['_PP']}\n",
    "            \n",
    "        for r in [S, NP, VP, PP]:\n",
    "            result.update(r)\n",
    "        return result\n",
    "\n",
    "def generate_NP(list_tag):\n",
    "    result = []\n",
    "    for tag in list_tag:\n",
    "        for words in NP:\n",
    "            if re.search(r'\\b' + tag + r'\\b', words):\n",
    "                result.append(words)\n",
    "    return list(OrderedDict.fromkeys(result))\n",
    "    \n",
    "def check_VP(list_tag):\n",
    "    for tag in list_tag:\n",
    "        if 'V' in tag:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def generate_VP(list_tag):\n",
    "    result = []\n",
    "    for tag in list_tag:\n",
    "        for words in VP:\n",
    "            if re.search(r'\\b' + tag + r'\\b', words):\n",
    "                result.append(words)\n",
    "    return list(OrderedDict.fromkeys(result))\n",
    "\n",
    "def remove_JJ(list_tag):\n",
    "    result = []\n",
    "    for tag in list_tag:\n",
    "        if '_JJ' in tag:\n",
    "            continue\n",
    "        else:\n",
    "            result.append(tag)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words_grammar(dict_words_by_tag):\n",
    "    result = {}\n",
    "    IN = {\"_IN\": ['di', 'dengan', 'untuk']}\n",
    "    CC = {\"_CC\": ['dan', 'mau']}\n",
    "    SC = {\"_SC\": ['yang']}\n",
    "    RB = {\"_RB\": ['sedang', 'sambil', 'masih', 'lagi']}\n",
    "    DT = {\"_DT\": ['itu']}\n",
    "    MD = {\"_MD\": ['bisa', 'telah', 'sudah']}\n",
    "    ADD_VBT = {\"_VBT\": ['ingin', 'pengin']}\n",
    "    ADD_VBI = {\"_VBI\": ['ada', 'suka']}\n",
    "    \n",
    "    WORDS = dict_words_by_tag\n",
    "    if '_VBT' in WORDS:\n",
    "        for word in ADD_VBT[\"_VBT\"]:\n",
    "            if word not in WORDS['_VBT']:\n",
    "                WORDS['_VBT'].append(word)\n",
    "    else:\n",
    "        WORDS.update(ADD_VBT)\n",
    "    \n",
    "    if '_VBI' in WORDS:\n",
    "        for word in ADD_VBI[\"_VBI\"]:\n",
    "            if word not in WORDS['_VBI']:\n",
    "                WORDS['_VBI'].append(word)\n",
    "    else:\n",
    "        WORDS.update(ADD_VBI)  \n",
    "            \n",
    "    for r in [IN, CC, SC, RB, DT, MD, WORDS]:\n",
    "        result.update(r)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_words_by_tag(list_words):\n",
    "    result = defaultdict(list)\n",
    "    \n",
    "    i = []\n",
    "    for s in list_words:\n",
    "        word, pwz = s[0], s[1]\n",
    "        \n",
    "        wrd = word.split('/')[0]\n",
    "        tag = word.split('/')[1]\n",
    "        result['_'+tag].append([wrd, pwz])\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word_pwz(dict_words_pwz_by_tag):\n",
    "    dict_word_by_tag = defaultdict(list)\n",
    "    dict_pwz_by_tag = defaultdict(list)\n",
    "    \n",
    "    for key, values in dict_words_pwz_by_tag.items():\n",
    "        for data in values:\n",
    "            word, pwz = data[0], data[1]\n",
    "            dict_word_by_tag[key].append(word)\n",
    "            dict_pwz_by_tag[key].append(pwz)\n",
    "    return dict(dict_word_by_tag), dict(dict_pwz_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(dict_words_by_topic):\n",
    "    grammar = {}\n",
    "    \n",
    "    dict_words_pwz_by_tag = organize_words_by_tag(dict_words_by_topic)\n",
    "    list_tag = get_list_tag(dict_words_pwz_by_tag)\n",
    "    base_grammar = generate_base_grammar(list_tag)\n",
    "    dict_word_by_tag, dict_pwz_by_tag = split_word_pwz(dict_words_pwz_by_tag)\n",
    "    words_grammar = generate_words_grammar(dict_word_by_tag)\n",
    "    \n",
    "    for r in [base_grammar, words_grammar]:\n",
    "        grammar.update(r)\n",
    "    return grammar, dict_pwz_by_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal(token):\n",
    "    return token[0] != \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_random = random.SystemRandom()\n",
    "\n",
    "def expand(grammar, tokens, dict_pwz_by_tag):\n",
    "#     print(tokens)\n",
    "    for i, token in enumerate(tokens):\n",
    "\n",
    "        # skip over terminals\n",
    "        if is_terminal(token): continue\n",
    "\n",
    "        # if we get here, we found a non-terminal token\n",
    "        # so we need to choose a replacement at random\n",
    "        replacement = sys_random.choice(grammar[token])\n",
    "        \n",
    "        if replacement == '_NN':\n",
    "            weight = [x/sum(dict_pwz_by_tag['_NN']) for x in dict_pwz_by_tag['_NN']]\n",
    "            replacement = nr.choice(grammar['_NN'], p=weight)\n",
    "#             print(grammar['_NN'], weight)\n",
    "            \n",
    "        if is_terminal(replacement):\n",
    "            tokens[i] = replacement\n",
    "        else:\n",
    "            tokens = tokens[:i] + replacement.split() + tokens[(i+1):]\n",
    "       \n",
    "        # now call expand on the new list of tokens\n",
    "        return expand(grammar, tokens, dict_pwz_by_tag)\n",
    "\n",
    "    # if we get here we had all terminals and are done\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(grammar, dict_pwz_by_tag):\n",
    "    return expand(grammar, [\"_S\"], dict_pwz_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences_from_data(dict_data):\n",
    "    result = {}\n",
    "    for topic, words in dict_data.items():\n",
    "        sentence = []\n",
    "        grammar, dict_pwz_by_tag = create_grammar(words)\n",
    "#         print(grammar)\n",
    "        for s in range(10):\n",
    "            sentence.append(' '.join(generate_sentence(grammar, dict_pwz_by_tag)))\n",
    "        result = merge_two_dicts(result, {topic: sentence})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_story = create_sentences_from_data(dict(dict_ldapwz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['ibunya ada',\n",
       "  'bequest ingin rajin ani',\n",
       "  'hari bisa membantu rajin',\n",
       "  'hari ada',\n",
       "  'pasar membantu ayu itu',\n",
       "  'seorang memiliki ani itu',\n",
       "  'hari lagi ingin gita',\n",
       "  'domba masih memiliki ibunya',\n",
       "  'ani ingin ani itu',\n",
       "  'pasar membantu ani itu'],\n",
       " 1: ['aku berada',\n",
       "  'aku lagi ingin ombak',\n",
       "  'pantai sudah pengin angin',\n",
       "  'pantai ingin kesulitan baik',\n",
       "  'tengah bisa pengin ombak',\n",
       "  'aku ingin pantai',\n",
       "  'pantai ada',\n",
       "  'ombak menderu angin daun',\n",
       "  'daun melihat daun yang ikhlas',\n",
       "  'ombak besar'],\n",
       " 2: ['orang yang adalah hidup',\n",
       "  'orang mempunyai anak itu',\n",
       "  'pedagang buruk',\n",
       "  'undangannya sudah adalah hidup',\n",
       "  'roda ingin pedagang itu',\n",
       "  'pedagang sudah ingin roda',\n",
       "  'roda sulit',\n",
       "  'hidup mempunyai hidup sulit',\n",
       "  'orang yang ingin pedagang',\n",
       "  'hidup mempunyai istrinya']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09090909090909091, 0.8181818181818181, 0.09090909090909091]\n"
     ]
    }
   ],
   "source": [
    "elements = ['one', 'two', 'three'] \n",
    "weights = [0.001, 0.009, 0.001]\n",
    "new_weight = [x/sum(weights) for x in weights]\n",
    "\n",
    "from numpy.random import choice\n",
    "# print(choice(elements, p=new_weight))\n",
    "print(new_weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
