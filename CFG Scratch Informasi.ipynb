{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = [\"Lawang-Sewu memiliki sistem pendingin air di bawah lantai, dan di atap. Itulah fungsi utama basement #lawangsewu\",\n",
    "            \"lawang-sewu berada di ujung Bodjongweg atau yang sekarang dikenal dengan nama Jalan Pemuda\",\n",
    "            \"lawang-sewu pernah digunakan sebagai penjara bawah tanah oleh serdadu Jepang.\",\n",
    "            \"lawang-sewu merupakan landmark Kota Semarang yang paling dikenal para turis baik lokal maupun asing\",\n",
    "            \"Lawang-Sewu adalah salah satu bangunan bersejarah yang dibangun oleh pemerintahan kolonial Belanda, pada 27 Februari 1904.\",\n",
    "            \"lawang-sewu dulu menjadi lokasi pertempuran yang hebat antara pemuda Angkatan Muda Kereta Api melawan Kempetai dan Kidobutai Jepang\",\n",
    "            \"Masyarakat setempat menyebutnya Lawang-Sewu (Seribu Pintu) dikarenakan bangunan tersebut memiliki pintu yang sangat banyak.\",\n",
    "            \"Lawang-Sewu dibangun pada tahun 1904 dan selesai pada tahun 1907. Terletak di bundaran Tugu Muda yang dahulu disebut Wilhelminaplein.\",\n",
    "            \"Lawang-Sewu tempo doeloe. Ada kereta api lewat juga di depannya.\",\n",
    "            \"di lantai dua terdapat aula besar yg dulu digunakan sebagai ruang pesta. Di sudut aula terpasang wastafel yg sudah ada sejak pertma kali lawang-sewu dibangun.\"]\n",
    "len(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from preprocess.normalize import Normalize\n",
    "from preprocess.tokenize import Tokenize\n",
    "from preprocess.symspell import SymSpell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionary...\n",
      "Processing dictionary...\n",
      "Copied 94811 words to master dictionary...\n",
      "Copied 679534 hashes to master dictionary...\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "normalizer = Normalize()\n",
    "tokenizer = Tokenize()\n",
    "symspell = SymSpell(max_dictionary_edit_distance=3)\n",
    "symspell.load_complete_model_from_json('preprocess\\data\\corpus_complete_model.json', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do process\n",
    "doc_preprocessed = []\n",
    "\n",
    "for tweet in document:\n",
    "    # normalize\n",
    "    tweet_norm = normalizer.remove_ascii_unicode(tweet)\n",
    "    tweet_norm = normalizer.remove_rt_fav(tweet_norm)\n",
    "    tweet_norm = normalizer.lower_text(tweet_norm)\n",
    "    tweet_norm = normalizer.remove_newline(tweet_norm)\n",
    "    tweet_norm = normalizer.remove_url(tweet_norm)\n",
    "    tweet_norm = normalizer.remove_emoticon(tweet_norm)\n",
    "    tweet_norm = normalizer.remove_hashtag_mention(tweet_norm)\n",
    "    tweet_norm = normalizer.remove_punctuation(tweet_norm)\n",
    "    \n",
    "    # tokenize\n",
    "    tweet_tok = tokenizer.WordTokenize(tweet_norm, removepunct=True)\n",
    "    \n",
    "    # spell correction\n",
    "    temp = []\n",
    "    for token in tweet_tok:\n",
    "        suggestion = symspell.lookup(phrase=token, verbosity=1, max_edit_distance=3)\n",
    "\n",
    "        # option if there is no suggestion\n",
    "        if len(suggestion) > 0:\n",
    "            get_suggestion = str(suggestion[0]).split(':')[0]\n",
    "            temp.append(get_suggestion)\n",
    "        else:\n",
    "            temp.append(token)\n",
    "    tweet_prepared = ' '.join(temp)\n",
    "    \n",
    "    doc_preprocessed.append(tweet_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lawang-sewu memiliki sistem pendingin air di bawah lantai dan di atap itulah fungsi utama basement',\n",
       " 'lawang-sewu berada di ujung bodjongweg atau yang sekarang dikenal dengan nama jalan pemuda',\n",
       " 'lawang-sewu pernah digunakan sebagai penjara bawah tanah oleh serdadu jepang',\n",
       " 'lawang-sewu merupakan landmark kota semarang yang paling dikenal para turis baik lokal maupun asing',\n",
       " 'lawang-sewu adalah salah satu bangunan bersejarah yang dibangun oleh pemerintahan kolonial belanda pada 27 februari 1904',\n",
       " 'lawang-sewu dulu menjadi lokasi pertempuran yang hebat antara pemuda angkatan muda kereta api melawan kempetai dan kidobutai jepang',\n",
       " 'masyarakat setempat menyebutnya lawang-sewu seribu pintu dikarenakan bangunan tersebut memiliki pintu yang sangat banyak',\n",
       " 'lawang-sewu dibangun pada tahun 1904 dan selesai pada tahun 907 terletak di bundaran tugu muda yang dahulu disebut wilhelminaplein',\n",
       " 'lawang-sewu tempo doeloe ada kereta api lewat juga di depannya',\n",
       " 'di lantai dua terdapat aula besar di dulu digunakan sebagai ruang pesta di sudut aula terpasang wastafel di sudah ada sejak pertama kali lawang-sewu dibangun']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSLDA\n",
    "## HMM Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from hmmtagger.tagger import MainTagger\n",
    "from tokenization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "tagger = MainTagger(\"resource/Lexicon.trn\", \"resource/Ngram.trn\", 0, 3, 3, 0, 0, False, 0.2, 0, 500.0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do process\n",
    "doc_tagged = []\n",
    "\n",
    "for tweet in doc_preprocessed:\n",
    "    if len(tweet) == 0: continue\n",
    "    out = sentence_extraction(cleaning(tweet))\n",
    "\n",
    "    join_token = []\n",
    "    for o in out:\n",
    "        strtag = \" \".join(tokenisasi_kalimat(o)).strip()\n",
    "        join_token.extend(tagger.taggingStr(strtag))\n",
    "    doc_tagged.append(' '.join(join_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lawang-sewu/NN memiliki/VBT sistem/NN pendingin/NN air/NN di/IN bawah/NN lantai/NN dan/CC di/IN atap/IN itulah/DT fungsi/NN utama/JJ basement/NN',\n",
       " 'lawang-sewu/NN berada/VBI di/IN ujung/VBT bodjongweg/NN atau/CC yang/SC sekarang/NN dikenal/VBT dengan/IN nama/NN jalan/NN pemuda/NN',\n",
       " 'lawang-sewu/NN pernah/RB digunakan/VBT sebagai/IN penjara/NN bawah/NN tanah/NN oleh/IN serdadu/NN jepang/NN',\n",
       " 'lawang-sewu/NN merupakan/VBT landmark/NN kota/NN semarang/NN yang/SC paling/RB dikenal/VBT para/DT turis/NN baik/JJ lokal/NN maupun/CC asing/JJ',\n",
       " 'lawang-sewu/NN adalah/VBT salah/JJ satu/CDP bangunan/NN bersejarah/VBI yang/SC dibangun/VBT oleh/IN pemerintahan/NN kolonial/JJ belanda/NN pada/IN 27/CDP februari/NN 1904/CDP',\n",
       " 'lawang-sewu/NN dulu/RB menjadi/VBT lokasi/NN pertempuran/NN yang/SC hebat/JJ antara/IN pemuda/NN angkatan/NN muda/JJ kereta/NN api/NN melawan/VBT kempetai/NN dan/CC kidobutai/NN jepang/NN',\n",
       " 'masyarakat/NN setempat/NN menyebutnya/VBT lawang-sewu/NN seribu/NN pintu/NN dikarenakan/VBT bangunan/NN tersebut/DT memiliki/VBT pintu/NN yang/SC sangat/RB banyak/JJ',\n",
       " 'lawang-sewu/NN dibangun/VBT pada/IN tahun/NN 1904/CDP dan/CC selesai/NN pada/IN tahun/NN 907/CDP terletak/VBI di/IN bundaran/NN tugu/NN muda/JJ yang/SC dahulu/JJ disebut/VBT wilhelminaplein/NN',\n",
       " 'lawang-sewu/NN tempo/NN doeloe/NN ada/VBI kereta/NN api/NN lewat/NN juga/RB di/IN depannya/NN',\n",
       " 'di/IN lantai/NN dua/CDP terdapat/VBT aula/NN besar/JJ di/IN dulu/RB digunakan/VBT sebagai/IN ruang/NN pesta/NN di/IN sudut/NNP aula/NN terpasang/VBI wastafel/NN di/IN sudah/MD ada/VBI sejak/IN pertama/CDO kali/NN lawang-sewu/NN dibangun/VBT']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kelas Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define\n",
    "Ccon = ['JJ', 'NN','NNP', 'NNG', 'VBI', 'VBT']\n",
    "Cfnc = ['OP', 'CP', 'GM', ';', ':', '\"', '.',\n",
    "         ',', '-', '...', 'RB', 'IN', 'MD', 'CC',\n",
    "         'SC', 'DT', 'UH', 'CDO', 'CDC', 'CDP', 'CDI',\n",
    "         'PRP', 'WP', 'PRN', 'PRL', 'NEG', 'SYM', 'RP', 'FW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do process\n",
    "doc_classified = []\n",
    "\n",
    "for tweet in doc_tagged:\n",
    "    tweet_split = tweet.split(' ')\n",
    "    \n",
    "    temp = {\"Content\": [], \"Function\": []}\n",
    "    con = []\n",
    "    fnc = []\n",
    "    \n",
    "    for token in tweet_split:\n",
    "        word = token.split('/', 1)[0]\n",
    "        tag = token.split('/', 1)[1]\n",
    "        \n",
    "        if tag in Ccon:\n",
    "            con.append(token)\n",
    "        elif tag in Cfnc:\n",
    "            fnc.append(token)\n",
    "            \n",
    "    temp[\"Content\"].append(' '.join(con))\n",
    "    temp[\"Function\"].append(' '.join(fnc))\n",
    "    \n",
    "    doc_classified.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Content': ['lawang-sewu/NN memiliki/VBT sistem/NN pendingin/NN air/NN bawah/NN lantai/NN fungsi/NN utama/JJ basement/NN'],\n",
       "  'Function': ['di/IN dan/CC di/IN atap/IN itulah/DT']},\n",
       " {'Content': ['lawang-sewu/NN berada/VBI ujung/VBT bodjongweg/NN sekarang/NN dikenal/VBT nama/NN jalan/NN pemuda/NN'],\n",
       "  'Function': ['di/IN atau/CC yang/SC dengan/IN']},\n",
       " {'Content': ['lawang-sewu/NN digunakan/VBT penjara/NN bawah/NN tanah/NN serdadu/NN jepang/NN'],\n",
       "  'Function': ['pernah/RB sebagai/IN oleh/IN']},\n",
       " {'Content': ['lawang-sewu/NN merupakan/VBT landmark/NN kota/NN semarang/NN dikenal/VBT turis/NN baik/JJ lokal/NN asing/JJ'],\n",
       "  'Function': ['yang/SC paling/RB para/DT maupun/CC']},\n",
       " {'Content': ['lawang-sewu/NN adalah/VBT salah/JJ bangunan/NN bersejarah/VBI dibangun/VBT pemerintahan/NN kolonial/JJ belanda/NN februari/NN'],\n",
       "  'Function': ['satu/CDP yang/SC oleh/IN pada/IN 27/CDP 1904/CDP']},\n",
       " {'Content': ['lawang-sewu/NN menjadi/VBT lokasi/NN pertempuran/NN hebat/JJ pemuda/NN angkatan/NN muda/JJ kereta/NN api/NN melawan/VBT kempetai/NN kidobutai/NN jepang/NN'],\n",
       "  'Function': ['dulu/RB yang/SC antara/IN dan/CC']},\n",
       " {'Content': ['masyarakat/NN setempat/NN menyebutnya/VBT lawang-sewu/NN seribu/NN pintu/NN dikarenakan/VBT bangunan/NN memiliki/VBT pintu/NN banyak/JJ'],\n",
       "  'Function': ['tersebut/DT yang/SC sangat/RB']},\n",
       " {'Content': ['lawang-sewu/NN dibangun/VBT tahun/NN selesai/NN tahun/NN terletak/VBI bundaran/NN tugu/NN muda/JJ dahulu/JJ disebut/VBT wilhelminaplein/NN'],\n",
       "  'Function': ['pada/IN 1904/CDP dan/CC pada/IN 907/CDP di/IN yang/SC']},\n",
       " {'Content': ['lawang-sewu/NN tempo/NN doeloe/NN ada/VBI kereta/NN api/NN lewat/NN depannya/NN'],\n",
       "  'Function': ['juga/RB di/IN']},\n",
       " {'Content': ['lantai/NN terdapat/VBT aula/NN besar/JJ digunakan/VBT ruang/NN pesta/NN sudut/NNP aula/NN terpasang/VBI wastafel/NN ada/VBI kali/NN lawang-sewu/NN dibangun/VBT'],\n",
       "  'Function': ['di/IN dua/CDP di/IN dulu/RB sebagai/IN di/IN di/IN sudah/MD sejak/IN pertama/CDO']}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lawang-sewu/NN memiliki/VBT sistem/NN pendingin/NN air/NN bawah/NN lantai/NN fungsi/NN utama/JJ basement/NN', 'lawang-sewu/NN berada/VBI ujung/VBT bodjongweg/NN sekarang/NN dikenal/VBT nama/NN jalan/NN pemuda/NN', 'lawang-sewu/NN digunakan/VBT penjara/NN bawah/NN tanah/NN serdadu/NN jepang/NN', 'lawang-sewu/NN merupakan/VBT landmark/NN kota/NN semarang/NN dikenal/VBT turis/NN baik/JJ lokal/NN asing/JJ', 'lawang-sewu/NN adalah/VBT salah/JJ bangunan/NN bersejarah/VBI dibangun/VBT pemerintahan/NN kolonial/JJ belanda/NN februari/NN', 'lawang-sewu/NN menjadi/VBT lokasi/NN pertempuran/NN hebat/JJ pemuda/NN angkatan/NN muda/JJ kereta/NN api/NN melawan/VBT kempetai/NN kidobutai/NN jepang/NN', 'masyarakat/NN setempat/NN menyebutnya/VBT lawang-sewu/NN seribu/NN pintu/NN dikarenakan/VBT bangunan/NN memiliki/VBT pintu/NN banyak/JJ', 'lawang-sewu/NN dibangun/VBT tahun/NN selesai/NN tahun/NN terletak/VBI bundaran/NN tugu/NN muda/JJ dahulu/JJ disebut/VBT wilhelminaplein/NN', 'lawang-sewu/NN tempo/NN doeloe/NN ada/VBI kereta/NN api/NN lewat/NN depannya/NN', 'lantai/NN terdapat/VBT aula/NN besar/JJ digunakan/VBT ruang/NN pesta/NN sudut/NNP aula/NN terpasang/VBI wastafel/NN ada/VBI kali/NN lawang-sewu/NN dibangun/VBT']\n",
      "\n",
      "[['lawang-sewu', 'memiliki', 'sistem', 'pendingin', 'air', 'bawah', 'lantai', 'fungsi', 'utama', 'basement'], ['lawang-sewu', 'berada', 'ujung', 'bodjongweg', 'sekarang', 'dikenal', 'nama', 'jalan', 'pemuda'], ['lawang-sewu', 'digunakan', 'penjara', 'bawah', 'tanah', 'serdadu', 'jepang'], ['lawang-sewu', 'merupakan', 'landmark', 'kota', 'semarang', 'dikenal', 'turis', 'baik', 'lokal', 'asing'], ['lawang-sewu', 'adalah', 'salah', 'bangunan', 'bersejarah', 'dibangun', 'pemerintahan', 'kolonial', 'belanda', 'februari'], ['lawang-sewu', 'menjadi', 'lokasi', 'pertempuran', 'hebat', 'pemuda', 'angkatan', 'muda', 'kereta', 'api', 'melawan', 'kempetai', 'kidobutai', 'jepang'], ['masyarakat', 'setempat', 'menyebutnya', 'lawang-sewu', 'seribu', 'pintu', 'dikarenakan', 'bangunan', 'memiliki', 'pintu', 'banyak'], ['lawang-sewu', 'dibangun', 'tahun', 'selesai', 'tahun', 'terletak', 'bundaran', 'tugu', 'muda', 'dahulu', 'disebut', 'wilhelminaplein'], ['lawang-sewu', 'tempo', 'doeloe', 'ada', 'kereta', 'api', 'lewat', 'depannya'], ['lantai', 'terdapat', 'aula', 'besar', 'digunakan', 'ruang', 'pesta', 'sudut', 'aula', 'terpasang', 'wastafel', 'ada', 'kali', 'lawang-sewu', 'dibangun']]\n"
     ]
    }
   ],
   "source": [
    "# split document content and function\n",
    "doc_content = []\n",
    "for tweet in doc_classified:\n",
    "    doc_content.append(''.join(tweet['Content']))\n",
    "\n",
    "print(doc_content)\n",
    "print()\n",
    "\n",
    "# split tag and word\n",
    "doc_prepared = []\n",
    "for tweet in doc_content:\n",
    "    tweet_split = tweet.split(' ')\n",
    "    \n",
    "    temp = []\n",
    "    for token in tweet_split:\n",
    "        word = token.split('/', 1)[0]\n",
    "        temp.append(word)\n",
    "    \n",
    "    doc_prepared.append(temp)\n",
    "\n",
    "print(doc_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from lda.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# iniatialize\n",
    "k = 2\n",
    "alpha = 0.01\n",
    "beta = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# do process\n",
    "lda = LdaModel(doc_prepared, k, alpha, beta, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lda.get_topic_word_pwz(doc_content)\n",
    "\n",
    "df_lda = pd.DataFrame(result, columns=['Topik', 'Kata', 'PWZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topik</th>\n",
       "      <th>Kata</th>\n",
       "      <th>PWZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lawang-sewu/NN</td>\n",
       "      <td>0.105810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dibangun/VBT</td>\n",
       "      <td>0.052993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bangunan/NN</td>\n",
       "      <td>0.035387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>memiliki/VBT</td>\n",
       "      <td>0.035387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>pintu/NN</td>\n",
       "      <td>0.035387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topik            Kata       PWZ\n",
       "0      0  lawang-sewu/NN  0.105810\n",
       "1      0    dibangun/VBT  0.052993\n",
       "2      0     bangunan/NN  0.035387\n",
       "3      0    memiliki/VBT  0.035387\n",
       "4      0        pintu/NN  0.035387"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.105810\n",
      "0.052993\n",
      "0.035387\n",
      "0.035387\n",
      "0.035387\n",
      "0.035387\n",
      "0.035387\n",
      "0.035387\n",
      "0.035387\n",
      "0.017782\n",
      "0.017782\n",
      "0.017782\n",
      "0.017782\n",
      "0.017782\n",
      "0.017782\n",
      "0.017782\n",
      "0.017782\n",
      "0.017782\n",
      "0.017782\n",
      "0.017782\n"
     ]
    }
   ],
   "source": [
    "print(df_lda[df_lda['Topik']==0]['PWZ'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.016035741399591"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.perplexity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dict_ldapwz = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_lda.iterrows():\n",
    "#     dict_ldapwz[row['Topik']].append(row['Kata'])\n",
    "    dict_ldapwz[row['Topik']].append([row['Kata'], row['PWZ']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [['lawang-sewu/NN', 0.10580985915492958],\n",
       "              ['dibangun/VBT', 0.05299295774647887],\n",
       "              ['bangunan/NN', 0.03538732394366197],\n",
       "              ['memiliki/VBT', 0.03538732394366197],\n",
       "              ['pintu/NN', 0.03538732394366197],\n",
       "              ['tahun/NN', 0.03538732394366197],\n",
       "              ['lantai/NN', 0.03538732394366197],\n",
       "              ['bawah/NN', 0.03538732394366197],\n",
       "              ['digunakan/VBT', 0.03538732394366197],\n",
       "              ['sistem/NN', 0.01778169014084507],\n",
       "              ['basement/NN', 0.01778169014084507],\n",
       "              ['penjara/NN', 0.01778169014084507],\n",
       "              ['jepang/NN', 0.01778169014084507],\n",
       "              ['salah/JJ', 0.01778169014084507],\n",
       "              ['bersejarah/VBI', 0.01778169014084507],\n",
       "              ['pemerintahan/NN', 0.01778169014084507],\n",
       "              ['belanda/NN', 0.01778169014084507],\n",
       "              ['februari/NN', 0.01778169014084507],\n",
       "              ['muda/JJ', 0.01778169014084507],\n",
       "              ['setempat/NN', 0.01778169014084507]],\n",
       "             1: [['lawang-sewu/NN', 0.07893700787401575],\n",
       "              ['kereta/NN', 0.039566929133858265],\n",
       "              ['api/NN', 0.039566929133858265],\n",
       "              ['ada/VBI', 0.039566929133858265],\n",
       "              ['aula/NN', 0.039566929133858265],\n",
       "              ['dikenal/VBT', 0.039566929133858265],\n",
       "              ['pemuda/NN', 0.039566929133858265],\n",
       "              ['berada/VBI', 0.01988188976377953],\n",
       "              ['sekarang/NN', 0.01988188976377953],\n",
       "              ['nama/NN', 0.01988188976377953],\n",
       "              ['merupakan/VBT', 0.01988188976377953],\n",
       "              ['landmark/NN', 0.01988188976377953],\n",
       "              ['turis/NN', 0.01988188976377953],\n",
       "              ['lokal/NN', 0.01988188976377953],\n",
       "              ['asing/JJ', 0.01988188976377953],\n",
       "              ['menjadi/VBT', 0.01988188976377953],\n",
       "              ['pertempuran/NN', 0.01988188976377953],\n",
       "              ['hebat/JJ', 0.01988188976377953],\n",
       "              ['angkatan/NN', 0.01988188976377953],\n",
       "              ['kempetai/NN', 0.01988188976377953]]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ldapwz"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_grammar = \"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> NN | NN NN | NN JJ | NNG | NNP |  NP PP |\n",
    "    VP -> VBT NN | VBT NN NN | VBT NN CC NN | VBT NP | VBI | JJ\n",
    "    PP -> IN NP\n",
    "    IN -> 'di'\n",
    "    VBT -> 'memiliki', 'adalah', 'merupakan', 'terdapat', 'yaitu', 'sebagai', 'mempunyai'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NP = ['_NN', '_NNG', '_NNP', '_NP _PP']\n",
    "VP = ['_VBT _NN', '_VBT _NN _CC _NN', '_VBT _NP', '_VBI', '_SC _JJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_tag(dict_words_by_tag):\n",
    "    result = []\n",
    "    for key in dict_words_by_tag:\n",
    "        result.append(key)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_grammar(list_tag):\n",
    "    result = {}\n",
    "    \n",
    "    if '_VBT' not in list_tag:\n",
    "        list_tag.append('_VBT')\n",
    "    \n",
    "    S = {\"_S\": [\"_NP _VP\"]}\n",
    "    PP = {\"_PP\": [\"_IN _NP\"]}\n",
    "    \n",
    "    if '_JJ' in list_tag:\n",
    "        NP_RULES = generate_NP(list_tag)\n",
    "        NP = {\"_NP\": NP_RULES}\n",
    "        if check_VP(list_tag):\n",
    "            VP_RULES = ['_VP _PP', '_JJ'] + generate_VP(list_tag)\n",
    "            VP = {\"_VP\": VP_RULES}\n",
    "        else:\n",
    "            VP = {\"_VP\": ['_JJ']}\n",
    "\n",
    "        for r in [S, NP, VP, PP]:\n",
    "            result.update(r)\n",
    "        return result\n",
    "    else:\n",
    "        NP_RULES = remove_JJ(generate_NP(list_tag))\n",
    "        NP = {\"_NP\": NP_RULES}\n",
    "        if check_VP(list_tag):\n",
    "            VP_RULES = ['_VP _PP'] + remove_JJ(generate_VP(list_tag))\n",
    "            VP = {\"_VP\": VP_RULES}\n",
    "        else:\n",
    "            VP = {\"_VP\": ['_PP']}\n",
    "            \n",
    "        for r in [S, NP, VP, PP]:\n",
    "            result.update(r)\n",
    "        return result\n",
    "\n",
    "def generate_NP(list_tag):\n",
    "    result = []\n",
    "    for tag in list_tag:\n",
    "        for words in NP:\n",
    "            if re.search(r'\\b' + tag + r'\\b', words):\n",
    "                result.append(words)\n",
    "    return list(OrderedDict.fromkeys(result))\n",
    "    \n",
    "def check_VP(list_tag):\n",
    "    for tag in list_tag:\n",
    "        if 'V' in tag:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def generate_VP(list_tag):\n",
    "    result = []\n",
    "    for tag in list_tag:\n",
    "        for words in VP:\n",
    "            if re.search(r'\\b' + tag + r'\\b', words):\n",
    "                result.append(words)\n",
    "    return list(OrderedDict.fromkeys(result))\n",
    "\n",
    "def remove_JJ(list_tag):\n",
    "    result = []\n",
    "    for tag in list_tag:\n",
    "        if '_JJ' in tag:\n",
    "            continue\n",
    "        else:\n",
    "            result.append(tag)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words_grammar(dict_words_by_tag):\n",
    "    result = {}\n",
    "    IN = {\"_IN\": ['di', 'sebagai', 'oleh']}\n",
    "    CC = {\"_CC\": ['dan']}\n",
    "    SC = {\"_SC\": ['yang']}\n",
    "    ADD_VBT = {\"_VBT\": ['memiliki', 'adalah', 'merupakan', 'terdapat', 'yaitu', 'sebagai', 'mempunyai']}\n",
    "    \n",
    "    WORDS = dict_words_by_tag\n",
    "    if '_VBT' in WORDS:\n",
    "        for word in ADD_VBT[\"_VBT\"]:\n",
    "            if word not in WORDS['_VBT']:\n",
    "                WORDS['_VBT'].append(word)\n",
    "    else:\n",
    "        WORDS.update(ADD_VBT)\n",
    "            \n",
    "    for r in [IN, CC, SC, WORDS]:\n",
    "        result.update(r)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_words_by_tag(list_words):\n",
    "    result = defaultdict(list)\n",
    "    \n",
    "    i = []\n",
    "    for s in list_words:\n",
    "        word, pwz = s[0], s[1]\n",
    "        \n",
    "        wrd = word.split('/')[0]\n",
    "        tag = word.split('/')[1]\n",
    "        result['_'+tag].append([wrd, pwz])\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word_pwz(dict_words_pwz_by_tag):\n",
    "    dict_word_by_tag = defaultdict(list)\n",
    "    dict_pwz_by_tag = defaultdict(list)\n",
    "    \n",
    "    for key, values in dict_words_pwz_by_tag.items():\n",
    "        for data in values:\n",
    "            word, pwz = data[0], data[1]\n",
    "            dict_word_by_tag[key].append(word)\n",
    "            dict_pwz_by_tag[key].append(pwz)\n",
    "    return dict(dict_word_by_tag), dict(dict_pwz_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(dict_words_by_topic):\n",
    "    grammar = {}\n",
    "    \n",
    "    dict_words_pwz_by_tag = organize_words_by_tag(dict_words_by_topic)\n",
    "    list_tag = get_list_tag(dict_words_pwz_by_tag)\n",
    "    base_grammar = generate_base_grammar(list_tag)\n",
    "    dict_word_by_tag, dict_pwz_by_tag = split_word_pwz(dict_words_pwz_by_tag)\n",
    "    words_grammar = generate_words_grammar(dict_word_by_tag)\n",
    "    \n",
    "    for r in [base_grammar, words_grammar]:\n",
    "        grammar.update(r)\n",
    "    return grammar, dict_pwz_by_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal(token):\n",
    "    return token[0] != \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_random = random.SystemRandom()\n",
    "\n",
    "def expand(grammar, tokens, dict_pwz_by_tag):\n",
    "    for i, token in enumerate(tokens):\n",
    "\n",
    "        # skip over terminals\n",
    "        if is_terminal(token): continue\n",
    "\n",
    "        # if we get here, we found a non-terminal token\n",
    "        # so we need to choose a replacement at random\n",
    "        replacement = sys_random.choice(grammar[token])\n",
    "        \n",
    "        if replacement == '_NN':\n",
    "            weight = [x/sum(dict_pwz_by_tag['_NN']) for x in dict_pwz_by_tag['_NN']]\n",
    "            replacement = nr.choice(grammar['_NN'], p=weight)\n",
    "            \n",
    "        if is_terminal(replacement):\n",
    "            tokens[i] = replacement\n",
    "        else:\n",
    "            tokens = tokens[:i] + replacement.split() + tokens[(i+1):]\n",
    "       \n",
    "        # now call expand on the new list of tokens\n",
    "        return expand(grammar, tokens, dict_pwz_by_tag)\n",
    "\n",
    "    # if we get here we had all terminals and are done\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(grammar, dict_pwz_by_tag):\n",
    "    return expand(grammar, [\"_S\"], dict_pwz_by_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences_from_data(dict_data):\n",
    "    result = {}\n",
    "    for topic, words in dict_data.items():\n",
    "        sentence = []\n",
    "        grammar, dict_pwz_by_tag = create_grammar(words)\n",
    "        print(grammar)\n",
    "        for s in range(10):\n",
    "            sentence.append(' '.join(generate_sentence(grammar, dict_pwz_by_tag)))\n",
    "        result = merge_two_dicts(result, {topic: sentence})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_S': ['_NP _VP'], '_NP': ['_NN'], '_VP': ['_VP _PP', '_JJ', '_VBT _NN', '_VBT _NN _CC _NN', '_VBT _NP', '_SC _JJ', '_VBI'], '_PP': ['_IN _NP'], '_IN': ['di', 'sebagai', 'oleh'], '_CC': ['dan'], '_SC': ['yang'], '_NN': ['lawang-sewu', 'bangunan', 'pintu', 'tahun', 'lantai', 'bawah', 'sistem', 'basement', 'penjara', 'jepang', 'pemerintahan', 'belanda', 'februari', 'setempat'], '_VBT': ['dibangun', 'memiliki', 'digunakan', 'adalah', 'merupakan', 'terdapat', 'yaitu', 'sebagai', 'mempunyai'], '_JJ': ['salah', 'muda'], '_VBI': ['bersejarah']}\n",
      "{'_S': ['_NP _VP'], '_NP': ['_NN'], '_VP': ['_VP _PP', '_JJ', '_VBT _NN', '_VBT _NN _CC _NN', '_VBI', '_VBT _NP', '_SC _JJ'], '_PP': ['_IN _NP'], '_IN': ['di', 'sebagai', 'oleh'], '_CC': ['dan'], '_SC': ['yang'], '_NN': ['lawang-sewu', 'kereta', 'api', 'aula', 'pemuda', 'sekarang', 'nama', 'landmark', 'turis', 'lokal', 'pertempuran', 'angkatan', 'kempetai'], '_VBI': ['ada', 'berada'], '_VBT': ['dikenal', 'merupakan', 'menjadi', 'memiliki', 'adalah', 'terdapat', 'yaitu', 'sebagai', 'mempunyai'], '_JJ': ['asing', 'hebat']}\n"
     ]
    }
   ],
   "source": [
    "dict_story = create_sentences_from_data(dict(dict_ldapwz))\n",
    "# for _ in dict_story.items():\n",
    "#     print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['lawang-sewu mempunyai jepang',\n",
       "  'bangunan bersejarah',\n",
       "  'pemerintahan memiliki lawang-sewu dan pemerintahan sebagai lantai',\n",
       "  'lawang-sewu yang salah',\n",
       "  'belanda merupakan lantai dan bawah',\n",
       "  'lantai mempunyai bawah',\n",
       "  'lawang-sewu muda',\n",
       "  'jepang yang muda',\n",
       "  'belanda salah',\n",
       "  'pintu bersejarah'],\n",
       " 1: ['lawang-sewu berada',\n",
       "  'angkatan ada di api',\n",
       "  'pemuda mempunyai lawang-sewu',\n",
       "  'lawang-sewu ada',\n",
       "  'pemuda berada',\n",
       "  'sekarang asing di lawang-sewu',\n",
       "  'aula berada',\n",
       "  'kereta ada',\n",
       "  'lawang-sewu sebagai lokal',\n",
       "  'aula adalah kereta']}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_story"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{0: ['tahun muda muda',\n",
    "  'kereta yang muda dibangun jepang',\n",
    "  'bangunan yang muda dibangun bawah',\n",
    "  'tahun muda muda',\n",
    "  'lantai muda muda',\n",
    "  'pemuda yang muda muda',\n",
    "  'lawang-sewu adalah lantai muda',\n",
    "  'lawang-sewu memiliki lawang-sewu',\n",
    "  'pemuda muda',\n",
    "  'jepang muda']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09090909090909091, 0.8181818181818181, 0.09090909090909091]\n"
     ]
    }
   ],
   "source": [
    "elements = ['one', 'two', 'three'] \n",
    "weights = [0.001, 0.009, 0.001]\n",
    "new_weight = [x/sum(weights) for x in weights]\n",
    "\n",
    "from numpy.random import choice\n",
    "# print(choice(elements, p=new_weight))\n",
    "print(new_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
