{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.generate import generate, demo_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> NP VP\n",
      "NP -> Det N | NP PP\n",
      "PP -> P NP\n",
      "VP -> V NP | VP PP\n",
      "Det -> 'the' | 'a'\n",
      "N -> 'cat' | 'dog'\n",
      "V -> 'chased' | 'sat'\n",
      "P -> 'in' | 'on'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('grammarku.txt', 'r') as myfile:\n",
    "    data = myfile.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 14 productions (start state = S)\n",
      "    S -> NP VP\n",
      "    NP -> Det N\n",
      "    NP -> NP PP\n",
      "    PP -> P NP\n",
      "    VP -> V NP\n",
      "    VP -> VP PP\n",
      "    Det -> 'the'\n",
      "    Det -> 'a'\n",
      "    N -> 'cat'\n",
      "    N -> 'dog'\n",
      "    V -> 'chased'\n",
      "    V -> 'sat'\n",
      "    P -> 'in'\n",
      "    P -> 'on'\n"
     ]
    }
   ],
   "source": [
    "gram = CFG.fromstring(data)\n",
    "print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = CFG.fromstring(demo_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 13 productions (start state = S)\n",
      "    S -> NP VP\n",
      "    NP -> Det N\n",
      "    PP -> P NP\n",
      "    VP -> 'slept'\n",
      "    VP -> 'saw' NP\n",
      "    VP -> 'walked' PP\n",
      "    Det -> 'the'\n",
      "    Det -> 'a'\n",
      "    N -> 'man'\n",
      "    N -> 'park'\n",
      "    N -> 'dog'\n",
      "    P -> 'in'\n",
      "    P -> 'with'\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cat chased the cat\n",
      "the cat chased the dog\n",
      "the cat chased a cat\n",
      "the cat chased a dog\n",
      "the cat chased the cat in the cat\n",
      "the cat chased the cat in the dog\n",
      "the cat chased the cat in a cat\n",
      "the cat chased the cat in a dog\n",
      "the cat chased the cat in the cat in the cat\n",
      "the cat chased the cat in the cat in the dog\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(gram, n=10):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cat chased the cat\n",
      "the cat chased the dog\n",
      "the cat chased a cat\n",
      "the cat chased a dog\n",
      "the cat sat the cat\n",
      "the cat sat the dog\n",
      "the cat sat a cat\n",
      "the cat sat a dog\n",
      "the dog chased the cat\n",
      "the dog chased the dog\n",
      "the dog chased a cat\n",
      "the dog chased a dog\n",
      "the dog sat the cat\n",
      "the dog sat the dog\n",
      "the dog sat a cat\n",
      "the dog sat a dog\n",
      "a cat chased the cat\n",
      "a cat chased the dog\n",
      "a cat chased a cat\n",
      "a cat chased a dog\n",
      "a cat sat the cat\n",
      "a cat sat the dog\n",
      "a cat sat a cat\n",
      "a cat sat a dog\n",
      "a dog chased the cat\n",
      "a dog chased the dog\n",
      "a dog chased a cat\n",
      "a dog chased a dog\n",
      "a dog sat the cat\n",
      "a dog sat the dog\n",
      "a dog sat a cat\n",
      "a dog sat a dog\n"
     ]
    }
   ],
   "source": [
    "for sentence in generate(gram, depth=5):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(generate(g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in generate(gram):\n",
    "#     print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> Det N | Det N PP | 'I'\n",
    "    VP -> V NP | VP PP\n",
    "    Det -> 'an' | 'my'\n",
    "    N -> 'elephant' | 'pajamas'\n",
    "    V -> 'shot'\n",
    "    P -> 'in'\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    VP -> V NP | V NP PP\n",
    "    PP -> P NP\n",
    "    V -> \"saw\" | \"ate\" | \"walked\"\n",
    "    NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "    Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "    N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "    P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "grammar2 = nltk.data.load('file:mygrammar.cfg')\n",
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar2)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar3 = nltk.CFG.fromstring(\"\"\"\n",
    "  S  -> NP VP\n",
    "  NP -> Det Nom | PropN\n",
    "  Nom -> Adj Nom | N\n",
    "  VP -> V Adj | V NP | V S | V NP PP\n",
    "  PP -> P NP\n",
    "  PropN -> 'Buster' | 'Chatterer' | 'Joe'\n",
    "  Det -> 'the' | 'a'\n",
    "  N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log'\n",
    "  Adj  -> 'angry' | 'frightened' |  'little' | 'tall'\n",
    "  V ->  'chased'  | 'saw' | 'said' | 'thought' | 'was' | 'put'\n",
    "  P -> 'on'\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "sent = \"Mary saw a dog\".split()\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP-TMP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = {\n",
    "    \"_S\"  : [\"_NP _VP\"],\n",
    "    \"_NP\" : [\"_NN\", \n",
    "             \"_NN _DT\",\n",
    "             \"_NN _JJ\"],\n",
    "    \"_VP\" : [\"_VBI _NP\",\n",
    "             \"_VBI _IN _NP\",\n",
    "             \"_VBI _NP _PP\"],\n",
    "    \"_PP\" : [\"_IN _NP\"],\n",
    "    \"_NN\" : [\"shelter\", \"kampung\", \"pantai\", \"marina\", \"pelangi\", \"jalan\", \"simpang\"],\n",
    "    \"_VBI\": [\"naik\", \"turun\"],\n",
    "    \"_JJ\" : [\"deket\"],\n",
    "    \"_IN\" : [\"di\", \"ke\", \"dari\"],\n",
    "    \"_DT\" : [\"ini\", \"itu\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = {\n",
    "    \"_JJP\": [\"_JJ\",\n",
    "             \"_JJ _CC _JJ\"],\n",
    "    \"_S\"  : [\"_NP _VP\"],\n",
    "    \"_NP\" : [\"_NP _CC _NP\", \n",
    "             \"_NN _DT\",\n",
    "             \"_NN _JJP\",\n",
    "             \"_NN\"],\n",
    "    \"_VP\" : [\"_PP\"],\n",
    "    \"_PP\" : [\"_IN _NP\"],\n",
    "    \"_NN\" : [\"simpang\", \"arus\", \"menit\", \"lintas\", \"tugu\", \"parkir\", \"kawasan\", \"bawah\"],\n",
    "    \"_JJ\" : [\"lalu\", \"muda\"],\n",
    "    \"_IN\" : [\"di\", \"ke\", \"dari\"],\n",
    "    \"_DT\" : [\"ini\", \"itu\"],\n",
    "    \"_CC\" : [\"dan\", \"atau\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar2 = {\n",
    "    \"_S\"  : [\"_NP _VP\"],\n",
    "    \"_NP\" : [\"_NP _CC _NP\", \n",
    "             \"_NN _DT\",\n",
    "             \"_NN _JJP\",\n",
    "             \"_NN\"],\n",
    "    \"_VP\" : [\"_VBI _NP\",\n",
    "             \"_VBI _NP _PP\"],\n",
    "    \"_PP\" : [\"_IN _NP\"],\n",
    "    \"_JJP\": [\"_JJ\",\n",
    "             \"_JJ _CC _JJ\"],\n",
    "    \"_VBI\": ['memakan', 'melihat'],\n",
    "    \"_NN\" : [\"sapi\", \"kambing\", \"manusia\"],\n",
    "    \"_JJ\" : [\"gemuk\", \"kurus\"],\n",
    "    \"_IN\" : [\"di\", \"ke\", \"dari\"],\n",
    "    \"_DT\" : [\"ini\", \"itu\"],\n",
    "    \"_CC\" : [\"dan\", \"atau\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def is_terminal(token):\n",
    "    return token[0] != \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(grammar, tokens):\n",
    "    for i, token in enumerate(tokens):\n",
    "\n",
    "        # skip over terminals\n",
    "        if is_terminal(token): continue\n",
    "\n",
    "        # if we get here, we found a non-terminal token\n",
    "        # so we need to choose a replacement at random\n",
    "        replacement = random.choice(grammar[token])\n",
    "\n",
    "        if is_terminal(replacement):\n",
    "            tokens[i] = replacement\n",
    "        else:\n",
    "            tokens = tokens[:i] + replacement.split() + tokens[(i+1):]\n",
    "\n",
    "        # now call expand on the new list of tokens\n",
    "        return expand(grammar, tokens)\n",
    "\n",
    "    # if we get here we had all terminals and are done\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(grammar):\n",
    "    return expand(grammar, [\"_S\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kambing melihat kambing itu di manusia itu\n",
      "sapi melihat sapi ini atau sapi dan sapi\n",
      "manusia atau sapi kurus atau gemuk atau kambing kurus atau kurus dan sapi ini atau kambing kurus dan gemuk melihat sapi gemuk dari sapi\n",
      "manusia kurus melihat kambing gemuk\n",
      "manusia itu melihat kambing itu\n",
      "manusia melihat manusia itu atau kambing gemuk dan gemuk dan kambing itu ke sapi kurus atau kurus atau manusia kurus dan kurus\n",
      "kambing kurus atau gemuk memakan kambing ini di sapi itu\n",
      "kambing itu dan sapi gemuk dan kurus melihat manusia gemuk\n",
      "manusia memakan sapi\n",
      "manusia itu melihat manusia gemuk ke sapi\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(' '.join(generate_sentence(grammar2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
