{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wingdongi</td>\n",
       "      <td>10/22/2017 14:22</td>\n",
       "      <td>b'@washingtoen Kaya lu'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nujateng</td>\n",
       "      <td>10/22/2017 14:21</td>\n",
       "      <td>b'Gebyar Budaya Hari Santri Nasional 2017 di K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desupriyadi_</td>\n",
       "      <td>10/22/2017 14:21</td>\n",
       "      <td>b'@detikcom Jujur, bergantung pada paketan dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sq_stony</td>\n",
       "      <td>10/22/2017 14:21</td>\n",
       "      <td>b'@IHateJDollarz What'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fahmimuttaqiin</td>\n",
       "      <td>10/22/2017 14:21</td>\n",
       "      <td>b'@Alvvin29 @IndosatCare Hahahahaha.. Bener ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        created_at  \\\n",
       "0       wingdongi  10/22/2017 14:22   \n",
       "1        nujateng  10/22/2017 14:21   \n",
       "2    desupriyadi_  10/22/2017 14:21   \n",
       "3        sq_stony  10/22/2017 14:21   \n",
       "4  fahmimuttaqiin  10/22/2017 14:21   \n",
       "\n",
       "                                                text  \n",
       "0                            b'@washingtoen Kaya lu'  \n",
       "1  b'Gebyar Budaya Hari Santri Nasional 2017 di K...  \n",
       "2  b'@detikcom Jujur, bergantung pada paketan dat...  \n",
       "3                             b'@IHateJDollarz What'  \n",
       "4  b'@Alvvin29 @IndosatCare Hahahahaha.. Bener ba...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweets_5000.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_b(row):\n",
    "    return row[2:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>normalize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wingdongi</td>\n",
       "      <td>10/22/2017 14:22</td>\n",
       "      <td>b'@washingtoen Kaya lu'</td>\n",
       "      <td>@washingtoen Kaya lu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nujateng</td>\n",
       "      <td>10/22/2017 14:21</td>\n",
       "      <td>b'Gebyar Budaya Hari Santri Nasional 2017 di K...</td>\n",
       "      <td>Gebyar Budaya Hari Santri Nasional 2017 di Kab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desupriyadi_</td>\n",
       "      <td>10/22/2017 14:21</td>\n",
       "      <td>b'@detikcom Jujur, bergantung pada paketan dat...</td>\n",
       "      <td>@detikcom Jujur, bergantung pada paketan data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sq_stony</td>\n",
       "      <td>10/22/2017 14:21</td>\n",
       "      <td>b'@IHateJDollarz What'</td>\n",
       "      <td>@IHateJDollarz What</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fahmimuttaqiin</td>\n",
       "      <td>10/22/2017 14:21</td>\n",
       "      <td>b'@Alvvin29 @IndosatCare Hahahahaha.. Bener ba...</td>\n",
       "      <td>@Alvvin29 @IndosatCare Hahahahaha.. Bener banget</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        created_at  \\\n",
       "0       wingdongi  10/22/2017 14:22   \n",
       "1        nujateng  10/22/2017 14:21   \n",
       "2    desupriyadi_  10/22/2017 14:21   \n",
       "3        sq_stony  10/22/2017 14:21   \n",
       "4  fahmimuttaqiin  10/22/2017 14:21   \n",
       "\n",
       "                                                text  \\\n",
       "0                            b'@washingtoen Kaya lu'   \n",
       "1  b'Gebyar Budaya Hari Santri Nasional 2017 di K...   \n",
       "2  b'@detikcom Jujur, bergantung pada paketan dat...   \n",
       "3                             b'@IHateJDollarz What'   \n",
       "4  b'@Alvvin29 @IndosatCare Hahahahaha.. Bener ba...   \n",
       "\n",
       "                                           normalize  \n",
       "0                               @washingtoen Kaya lu  \n",
       "1  Gebyar Budaya Hari Santri Nasional 2017 di Kab...  \n",
       "2  @detikcom Jujur, bergantung pada paketan data ...  \n",
       "3                                @IHateJDollarz What  \n",
       "4   @Alvvin29 @IndosatCare Hahahahaha.. Bener banget  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['normalize'] = df['text'].apply(remove_b)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove unicode emoji\n",
    "def remove_emoji(row):\n",
    "    p = re.compile(r'\\\\\\w\\w\\d|\\\\[xf0]\\w[^\\d]', re.IGNORECASE)\n",
    "    return p.sub(\"\", row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @dns_dini: #HappyBirthday\\xe9\\x9e\\xa0\\xe5\\xa9\\xa7\\xe7\\xa5\\x8e0618 #kiku semoga bisa nomer 1 di ssk tahun ini amin \\nwish you all the best https://t.co/dslKXQeueE\n"
     ]
    }
   ],
   "source": [
    "print(df['normalize'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @dns_dini: #HappyBirthday0618 #kiku semoga bisa nomer 1 di ssk tahun ini amin \\nwish you all the best https://t.co/dslKXQeueE\n"
     ]
    }
   ],
   "source": [
    "df['normalize'] = df['normalize'].apply(remove_emoji)\n",
    "print(df['normalize'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove \\n\n",
    "def remove_n(row):\n",
    "    return re.sub(r\"(\\\\\\w(?=[^\\w]))|\\\\\\w(?=\\w\\w\\w\\w[^_][^:])|(?<=! \\\\\\w)\\\\\\w\", \" \", row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semester 6   simulasi diskusi panel  #moderator #discussion #panel #seminar #nasional #jurusan https://t.co/oMaH1gY8oS\n"
     ]
    }
   ],
   "source": [
    "df['normalize'] = df['normalize'].apply(remove_n)\n",
    "print(df['normalize'][141])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "def html_parser(row):\n",
    "    return html.unescape(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semester 6   simulasi diskusi panel  #moderator #discussion #panel #seminar #nasional #jurusan https://t.co/oMaH1gY8oS\n"
     ]
    }
   ],
   "source": [
    "df['normalize'] = df['normalize'].apply(html_parser)\n",
    "print(df['normalize'][141])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def standardizing_words(row):\n",
    "    return ''.join(''.join(s)[:2] for _, s in itertools.groupby(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semester 6  simulasi diskusi panel  #moderator #discussion #panel #seminar #nasional #jurusan https://t.co/oMaH1gY8oS\n"
     ]
    }
   ],
   "source": [
    "df['normalize'] = df['normalize'].apply(standardizing_words)\n",
    "print(df['normalize'][141])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_url(row):\n",
    "    return re.sub(r\"http\\S+\", \"\", row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semester 6  simulasi diskusi panel  #moderator #discussion #panel #seminar #nasional #jurusan \n"
     ]
    }
   ],
   "source": [
    "df['normalize'] = df['normalize'].apply(clean_url)\n",
    "print(df['normalize'][141])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modulenorm.modNormalize import normalize\n",
    "from modulenorm.modTokenizing import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for row in df['normalize']:\n",
    "    \n",
    "    # normalize\n",
    "    usenorm = normalize()\n",
    "    text_norm = usenorm.enterNormalize(row) # normalisasi enter, 1 revw 1 baris\n",
    "    text_norm = usenorm.lowerNormalize(text_norm) # normalisasi huruf besar ke kecil\n",
    "    text_norm = usenorm.repeatcharNormalize(text_norm) # normalisasi titik yang berulang\n",
    "    text_norm = usenorm.linkNormalize(text_norm) # normalisasi link dalam text\n",
    "    text_norm = usenorm.spacecharNormalize(text_norm) # normalisasi spasi karakter\n",
    "    text_norm = usenorm.ellipsisNormalize(text_norm) # normalisasi elepsis (â€¦)\n",
    "    \n",
    "    # tokenize\n",
    "    tok = tokenize() \n",
    "    text_norm = tok.WordTokenize(text_norm) # pisah tiap kata pada kalimat\n",
    "\n",
    "    text_norm = usenorm.spellNormalize(text_norm) # cek spell dari kata perkata\n",
    "#     text_norm = usenorm.wordcNormalize(text_norm,2) # menyambung kata (malam-malam) (param: textlist, jmlh_loop)\n",
    "    # text_norm = usenorm.stemmingNormalize(text_norm,'word') # mengubah ke bentuk kata dasar (text, type_data)\n",
    "\n",
    "    text_norm = ' '.join(text_norm) # menggabung kalimat tokenize dengan separate spasi\n",
    "\n",
    "    text_norm = usenorm.emoticonNormalize(text_norm) # menggabung struktur emoticon yang terpisah ([: - )] = [:-)])\n",
    "\n",
    "    # walking2\n",
    "    # konfer @ ke at untuk penunjuk tempat\n",
    "    \n",
    "#     output = open(\"output1.txt\",\"a\")\n",
    "#     output.write(str(text_norm))\n",
    "#     output.write('\\n')\n",
    "#     output.close()\n",
    "\n",
    "#     print(no, text_norm)\n",
    "    df['normalize2'][idx] = text_norm\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>normalize</th>\n",
       "      <th>normalize2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>arviirsya</td>\n",
       "      <td>10/22/2017 7:46</td>\n",
       "      <td>b'@nieaamelya Heuheu'</td>\n",
       "      <td>@nieaamelya Heuheu</td>\n",
       "      <td>@ nieaamelya heuheu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>nandar_art</td>\n",
       "      <td>10/22/2017 7:46</td>\n",
       "      <td>b'Pas jaman SBY ke semarang untuk meresmikan S...</td>\n",
       "      <td>Pas jaman SBY ke semarang untuk meresmikan SPA...</td>\n",
       "      <td>pas jaman sby ke semarang untuk meresmikan spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>sharameilyanti</td>\n",
       "      <td>10/22/2017 7:46</td>\n",
       "      <td>b'\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>Yusniiunii</td>\n",
       "      <td>10/22/2017 7:46</td>\n",
       "      <td>b'At Perum Bumi Pucang Gading Semarang [pic] \\...</td>\n",
       "      <td>At Perum Bumi Pucang Gading Semarang [pic]</td>\n",
       "      <td>at perum bumi pucang gading semarang [ pic ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>BEMUndip_</td>\n",
       "      <td>10/22/2017 7:46</td>\n",
       "      <td>b'#Advokesma\\n#JobNCareer\\n#CareerTNT https://...</td>\n",
       "      <td>#Advokesma #JobNCareer #CareerTNT</td>\n",
       "      <td># advokesma # jobncareer # careertnt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user       created_at  \\\n",
       "5104       arviirsya  10/22/2017 7:46   \n",
       "5105      nandar_art  10/22/2017 7:46   \n",
       "5106  sharameilyanti  10/22/2017 7:46   \n",
       "5107      Yusniiunii  10/22/2017 7:46   \n",
       "5108       BEMUndip_  10/22/2017 7:46   \n",
       "\n",
       "                                                   text  \\\n",
       "5104                              b'@nieaamelya Heuheu'   \n",
       "5105  b'Pas jaman SBY ke semarang untuk meresmikan S...   \n",
       "5106  b'\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94\\xa5\\xf0\\x9f\\x94...   \n",
       "5107  b'At Perum Bumi Pucang Gading Semarang [pic] \\...   \n",
       "5108  b'#Advokesma\\n#JobNCareer\\n#CareerTNT https://...   \n",
       "\n",
       "                                              normalize  \\\n",
       "5104                                 @nieaamelya Heuheu   \n",
       "5105  Pas jaman SBY ke semarang untuk meresmikan SPA...   \n",
       "5106                                                      \n",
       "5107       At Perum Bumi Pucang Gading Semarang [pic]     \n",
       "5108                 #Advokesma #JobNCareer #CareerTNT    \n",
       "\n",
       "                                             normalize2  \n",
       "5104                                @ nieaamelya heuheu  \n",
       "5105  pas jaman sby ke semarang untuk meresmikan spa...  \n",
       "5106                                                     \n",
       "5107       at perum bumi pucang gading semarang [ pic ]  \n",
       "5108               # advokesma # jobncareer # careertnt  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['normalize2'].to_csv('normalize2.csv', header=['tweets'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
